Running prologue on parent mom node: nid001472...
Job 17242461.cbqs01 nodelist: nid001472
Job 17242461.cbqs01 - Prologue complete. Execution time: 3 seconds
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=00 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17242470.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=01 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17242503.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=02 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17242533.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=03 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17242588.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=04 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17242725.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=05 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17242771.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=06 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17242811.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=07 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17242842.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=08 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17242915.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=09 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17242979.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=10 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17242997.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=11 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17243029.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=12 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17243053.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=13 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17243181.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=14 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17243218.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=15 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17243244.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=16 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17243268.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=17 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17243299.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=18 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17243346.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=19 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17243473.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=20 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17243523.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=21 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17243543.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=22 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17243567.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=23 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17243747.cbqs01
++ sleep 60
++ exit
Job 17242461.cbqs01 - Epilogue complete. Execution time: 1 seconds
==================================================================
BEGIN - DEBUG INFO
==================================================================
Job 17242461.cbqs01 - Post Job Mem Usage:
nid001472: 2022-10-31.06 1 ===========================================
nid001472: 2022-10-31.06 2 #### Node Memory Usage for nid001472 ####
nid001472: 2022-10-31.06 3 ------------------
nid001472: 2022-10-31.06 4 Mem: total:527077116 used:10944368 free:509352804 shared:4787744 cache:6779944 avail:508966636
nid001472: 2022-10-31.06 5 4.0K	/dev/shm
nid001472: 2022-10-31.06 6 15M	/tmp
nid001472: 2022-10-31.06 7 ===========================================
nid001472: 2022-10-31.13 1 ===========================================
nid001472: 2022-10-31.13 2 #### Node Memory Usage for nid001472 ####
nid001472: 2022-10-31.13 3 ------------------
nid001472: 2022-10-31.13 4 Mem: total:527077116 used:10946892 free:509400968 shared:4786616 cache:6729256 avail:508989232
nid001472: 2022-10-31.13 5 4.0K	/dev/shm
nid001472: 2022-10-31.13 6 15M	/tmp
nid001472: 2022-10-31.13 7 ===========================================

------------------------------------------------------------------
Job 17242461.cbqs01 - /var/log/messages for job duration:
nid001472: 2022-10-31A--:--:--.------+--:-- nid001472 #### nid001472 - Job 17242461.cbqs01 Runtime Data from /var/log/messages
nid001472: 2022-10-31T14:07:12.742098+00:00 nid001472 prologue: MARK: Job 17242461.cbqs01 Start
nid001472: 2022-10-31T14:07:12.748322+00:00 nid001472 prologue: Job 17242461.cbqs01 nodelist: nid001472
nid001472: 2022-10-31T14:07:12.749441+00:00 nid001472 prologue: Job 17242461.cbqs01 - Checking existing ASLR settings...
nid001472: 2022-10-31T14:07:12.755296+00:00 nid001472 prologue: Job 17242461.cbqs01 - Checking palsd open file count...
nid001472: 2022-10-31T14:07:12.853946+00:00 nid001472 PBS_CMD: root : /opt/pbs/bin/qstat -Bf
nid001472: 2022-10-31T14:07:13.873992+00:00 nid001472 prologue: Job 17242461.cbqs01 - Checking one-shot control: False
nid001472: 2022-10-31T14:07:13.875054+00:00 nid001472 prologue: Job 17242461.cbqs01 - Recording pre-job HSN counters...
nid001472: 2022-10-31T14:07:13.981427+00:00 nid001472 prologue: Job 17242461.cbqs01 - Recording pre-job memory usage...
nid001472: 2022-10-31T14:07:14.014697+00:00 nid001472 prologue: Job 17242461.cbqs01 - Killing any stray user processes...
nid001472: 2022-10-31T14:07:14.087819+00:00 nid001472 prologue: Job 17242461.cbqs01 - Enabling turboboost...
nid001472: 2022-10-31T14:07:14.091397+00:00 nid001472 prologue: Job 17242461.cbqs01 - Verifying post-boot workarounds...
nid001472: 2022-10-31T14:07:14.428549+00:00 nid001472 prologue: Job 17242461.cbqs01 - Warchk Complete
nid001472: 2022-10-31T14:07:14.429687+00:00 nid001472 prologue: Job 17242461.cbqs01 - Recording initial NFS client statistics...
nid001472: 2022-10-31T14:07:14.438025+00:00 nid001472 prologue: Job 17242461.cbqs01 - Prologue complete. Execution time: 3 seconds
nid001472: 2022-10-31T14:07:36.695383+00:00 nid001472 systemd[1]: session-379197.scope: Succeeded.
nid001472: 2022-10-31T14:07:45.024284+00:00 nid001472 systemd[1]: session-379198.scope: Succeeded.
nid001472: 2022-10-31T14:08:16.664052+00:00 nid001472 systemd[1]: session-379199.scope: Succeeded.
nid001472: 2022-10-31T14:08:24.950664+00:00 nid001472 systemd[1]: session-379200.scope: Succeeded.
nid001472: 2022-10-31T14:08:57.254167+00:00 nid001472 systemd[1]: session-379201.scope: Succeeded.
nid001472: 2022-10-31T14:09:05.969332+00:00 nid001472 systemd[1]: session-379202.scope: Succeeded.
nid001472: 2022-10-31T14:09:36.495891+00:00 nid001472 systemd[1]: session-379203.scope: Succeeded.
nid001472: 2022-10-31T14:09:44.896455+00:00 nid001472 systemd[1]: session-379204.scope: Succeeded.
nid001472: 2022-10-31T14:10:24.300367+00:00 nid001472 systemd[1]: session-379205.scope: Succeeded.
nid001472: 2022-10-31T14:10:32.642135+00:00 nid001472 systemd[1]: session-379206.scope: Succeeded.
nid001472: 2022-10-31T14:10:41.726040+00:00 nid001472 systemd[1]: etc_update.service: Succeeded.
nid001472: 2022-10-31T14:10:56.554349+00:00 nid001472 systemd[1]: session-379207.scope: Succeeded.
nid001472: 2022-10-31T14:11:04.987376+00:00 nid001472 systemd[1]: session-379208.scope: Succeeded.
nid001472: 2022-10-31T14:11:36.579482+00:00 nid001472 systemd[1]: session-379209.scope: Succeeded.
nid001472: 2022-10-31T14:11:44.930464+00:00 nid001472 systemd[1]: session-379210.scope: Succeeded.
nid001472: 2022-10-31T14:12:16.575794+00:00 nid001472 systemd[1]: session-379211.scope: Succeeded.
nid001472: 2022-10-31T14:12:24.959889+00:00 nid001472 systemd[1]: session-379212.scope: Succeeded.
nid001472: 2022-10-31T14:12:56.552334+00:00 nid001472 systemd[1]: session-379213.scope: Succeeded.
nid001472: 2022-10-31T14:13:05.003370+00:00 nid001472 systemd[1]: session-379214.scope: Succeeded.
nid001472: 2022-10-31T14:13:36.601480+00:00 nid001472 systemd[1]: session-379215.scope: Succeeded.
nid001472: 2022-10-31T14:13:45.014676+00:00 nid001472 systemd[1]: session-379216.scope: Succeeded.
nid001472: 2022-10-31T14:14:16.567698+00:00 nid001472 systemd[1]: session-379217.scope: Succeeded.
nid001472: 2022-10-31T14:14:24.978748+00:00 nid001472 systemd[1]: session-379218.scope: Succeeded.
nid001472: 2022-10-31T14:14:56.683870+00:00 nid001472 systemd[1]: session-379219.scope: Succeeded.
nid001472: 2022-10-31T14:15:05.080573+00:00 nid001472 systemd[1]: session-379220.scope: Succeeded.
nid001472: 2022-10-31T14:15:44.949313+00:00 nid001472 systemd[1]: session-379221.scope: Succeeded.
nid001472: 2022-10-31T14:15:56.610287+00:00 nid001472 systemd[1]: session-379222.scope: Succeeded.
nid001472: 2022-10-31T14:16:21.627330+00:00 nid001472 systemd[1]: session-379223.scope: Succeeded.
nid001472: 2022-10-31T14:16:30.066973+00:00 nid001472 systemd[1]: session-379224.scope: Succeeded.
nid001472: 2022-10-31T14:17:01.656929+00:00 nid001472 systemd[1]: session-379225.scope: Succeeded.
nid001472: 2022-10-31T14:17:10.056472+00:00 nid001472 systemd[1]: session-379226.scope: Succeeded.
nid001472: 2022-10-31T14:17:41.941149+00:00 nid001472 systemd[1]: session-379227.scope: Succeeded.
nid001472: 2022-10-31T14:17:50.352856+00:00 nid001472 systemd[1]: session-379228.scope: Succeeded.
nid001472: 2022-10-31T14:18:21.748523+00:00 nid001472 systemd[1]: session-379229.scope: Succeeded.
nid001472: 2022-10-31T14:18:30.163753+00:00 nid001472 systemd[1]: session-379230.scope: Succeeded.
nid001472: 2022-10-31T14:18:56.580723+00:00 nid001472 systemd[1]: session-379231.scope: Succeeded.
nid001472: 2022-10-31T14:19:04.974338+00:00 nid001472 systemd[1]: session-379232.scope: Succeeded.
nid001472: 2022-10-31T14:19:36.565480+00:00 nid001472 systemd[1]: session-379233.scope: Succeeded.
nid001472: 2022-10-31T14:19:45.184146+00:00 nid001472 systemd[1]: session-379234.scope: Succeeded.
nid001472: 2022-10-31T14:20:08.721994+00:00 nid001472 systemd[1]: etc_update.service: Succeeded.
nid001472: 2022-10-31T14:20:27.892641+00:00 nid001472 systemd[1]: session-379235.scope: Succeeded.
nid001472: 2022-10-31T14:20:36.252128+00:00 nid001472 systemd[1]: session-379236.scope: Succeeded.
nid001472: 2022-10-31T14:21:06.760870+00:00 nid001472 systemd[1]: session-379237.scope: Succeeded.
nid001472: 2022-10-31T14:21:15.285645+00:00 nid001472 systemd[1]: session-379238.scope: Succeeded.
nid001472: 2022-10-31T14:21:46.586459+00:00 nid001472 systemd[1]: session-379239.scope: Succeeded.
nid001472: 2022-10-31T14:21:54.998047+00:00 nid001472 systemd[1]: session-379240.scope: Succeeded.
nid001472: 2022-10-31T14:22:26.562934+00:00 nid001472 systemd[1]: session-379241.scope: Succeeded.
nid001472: 2022-10-31T14:22:34.972358+00:00 nid001472 systemd[1]: session-379242.scope: Succeeded.
nid001472: 2022-10-31T14:23:06.643445+00:00 nid001472 systemd[1]: session-379243.scope: Succeeded.
nid001472: 2022-10-31T14:23:15.004688+00:00 nid001472 systemd[1]: session-379244.scope: Succeeded.
nid001472: 2022-10-31T14:23:46.626233+00:00 nid001472 systemd[1]: session-379245.scope: Succeeded.
nid001472: 2022-10-31T14:23:55.030716+00:00 nid001472 systemd[1]: session-379246.scope: Succeeded.
nid001472: 2022-10-31T14:24:26.543584+00:00 nid001472 systemd[1]: session-379247.scope: Succeeded.
nid001472: 2022-10-31T14:24:34.966723+00:00 nid001472 systemd[1]: session-379248.scope: Succeeded.
nid001472: 2022-10-31T14:25:06.609554+00:00 nid001472 systemd[1]: session-379249.scope: Succeeded.
nid001472: 2022-10-31T14:25:14.971870+00:00 nid001472 systemd[1]: session-379250.scope: Succeeded.
nid001472: 2022-10-31T14:25:46.597286+00:00 nid001472 systemd[1]: session-379251.scope: Succeeded.
nid001472: 2022-10-31T14:25:54.983136+00:00 nid001472 systemd[1]: session-379252.scope: Succeeded.
nid001472: 2022-10-31T14:26:26.600465+00:00 nid001472 systemd[1]: session-379253.scope: Succeeded.
nid001472: 2022-10-31T14:26:35.000880+00:00 nid001472 systemd[1]: session-379254.scope: Succeeded.
nid001472: 2022-10-31T14:27:06.611523+00:00 nid001472 systemd[1]: session-379255.scope: Succeeded.
nid001472: 2022-10-31T14:27:15.002485+00:00 nid001472 systemd[1]: session-379256.scope: Succeeded.
nid001472: 2022-10-31T14:27:46.665188+00:00 nid001472 systemd[1]: session-379257.scope: Succeeded.
nid001472: 2022-10-31T14:27:55.045146+00:00 nid001472 systemd[1]: session-379258.scope: Succeeded.
nid001472: 2022-10-31T14:28:26.581162+00:00 nid001472 systemd[1]: session-379259.scope: Succeeded.
nid001472: 2022-10-31T14:28:34.992731+00:00 nid001472 systemd[1]: session-379260.scope: Succeeded.
nid001472: 2022-10-31T14:29:06.568995+00:00 nid001472 systemd[1]: session-379261.scope: Succeeded.
nid001472: 2022-10-31T14:29:14.976705+00:00 nid001472 systemd[1]: session-379262.scope: Succeeded.
nid001472: 2022-10-31T14:29:47.171498+00:00 nid001472 systemd[1]: session-379263.scope: Succeeded.
nid001472: 2022-10-31T14:29:55.536998+00:00 nid001472 systemd[1]: session-379264.scope: Succeeded.
nid001472: 2022-10-31T14:30:41.398809+00:00 nid001472 systemd[1]: session-379265.scope: Succeeded.
nid001472: 2022-10-31T14:30:49.759715+00:00 nid001472 systemd[1]: session-379266.scope: Succeeded.
nid001472: 2022-10-31T14:31:21.607591+00:00 nid001472 systemd[1]: session-379267.scope: Succeeded.
nid001472: 2022-10-31T14:31:30.014288+00:00 nid001472 systemd[1]: session-379268.scope: Succeeded.
nid001472: 2022-10-31T14:32:01.778672+00:00 nid001472 systemd[1]: session-379269.scope: Succeeded.
nid001472: 2022-10-31T14:32:06.651785+00:00 nid001472 epilogue: Job 17242461.cbqs01 complete, running post-job actions.
nid001472: 2022-10-31T14:32:06.668531+00:00 nid001472 epilogue: Job 17242461.cbqs01 - Recording post-job HSN counters...
nid001472: 2022-10-31T14:32:06.785700+00:00 nid001472 epilogue: Job 17242461.cbqs01 - Recording post-job memory usage...
nid001472: 2022-10-31T14:32:06.803731+00:00 nid001472 epilogue: Job 17242461.cbqs01 - Recording job NFS statistics to /tmp/nfsstats.17242461.cbqs01
nid001472: 2022-10-31T14:32:07.304736+00:00 nid001472 epilogue: Job 17242461.cbqs01 - Clearing /tmp...
nid001472: 2022-10-31T14:32:07.321333+00:00 nid001472 epilogue: Job 17242461.cbqs01 - Clearing shared memory...
nid001472: 2022-10-31T14:32:07.334461+00:00 nid001472 epilogue: Job 17242461.cbqs01 - Clearing memory cache...
nid001472: 2022-10-31T14:32:07.651216+00:00 nid001472 kernel: [7607773.728009] drop_caches (100135): drop_caches: 3
nid001472: 2022-10-31T14:32:07.820768+00:00 nid001472 epilogue: Job 17242461.cbqs01 - Releasing Lustre Locks...
nid001472: 2022-10-31T14:32:07.835854+00:00 nid001472 epilogue: MARK: Job 17242461.cbqs01 Complete.

------------------------------------------------------------------
Job 17242461.cbqs01 - dmesg output for job duration:
nid001472: 2022-10-31A--:--:--.------+--:-- nid001472 #### nid001472 - Job 17242461.cbqs01 Runtime Data from dmesg
nid001472: [Mon Oct 31 14:05:42 2022] MARK: Job 17242461.cbqs01 Start
nid001472: [Mon Oct 31 14:30:37 2022] MARK: Job 17242461.cbqs01 Complete.
nid001472: [Mon Oct 31 14:30:37 2022] drop_caches (100135): drop_caches: 3

------------------------------------------------------------------
Job 17242461.cbqs01 - Pre/Post job diff on HSN (MLX) Counters:
nid001472: 2022-10-31A--:--:--.------+--:-- nid001472 #### nid001472 - Job 17242461.cbqs01 HSN0 MLX Counter Post-Job Difference
nid001472: multicast: 300125907					      |	multicast: 300126046
nid001472: port_rcv_data: 626832317576085				      |	port_rcv_data: 626832317905850
nid001472: port_rcv_packets: 951973662240				      |	port_rcv_packets: 951973668822
nid001472: port_xmit_data: 631959209517498				      |	port_xmit_data: 631959209864273
nid001472: port_xmit_packets: 957639032661				      |	port_xmit_packets: 957639039246
nid001472: rx_bytes: 687133575826					      |	rx_bytes: 687142596395
nid001472: rx_packets: 731535186					      |	rx_packets: 731549036
nid001472: tx_bytes: 281326960731					      |	tx_bytes: 281329277889
nid001472: tx_packets: 287753349					      |	tx_packets: 287768459
nid001472: unicast_rcv_packets: 951973662240			      |	unicast_rcv_packets: 951973668822
nid001472: unicast_xmit_packets: 957639032661			      |	unicast_xmit_packets: 957639039246

------------------------------------------------------------------
### Job 17242461.cbqs01 - NFS Statistics for job duration:
nid001472: #### 2022-10-31.00 #### nid001472 - Job 17242461.cbqs01 NFS Statistics for job duration (nfsstat)
nid001472: ## /usr/sbin/nfsstat -v -S /tmp/nfsstats.begin.17242461.cbqs01 :
nid001472: Client packet stats:
nid001472: packets    udp        tcp        tcpconn
nid001472: 0          0          0          0       
nid001472: 
nid001472: Client rpc stats:
nid001472: calls      retrans    authrefrsh
nid001472: 9063       0          9063    
nid001472: 
nid001472: Client nfs v3:
nid001472: null             getattr          setattr          lookup           access           
nid001472: 0         0%     8084     89%     2         0%     313       3%     314       3%     
nid001472: readlink         read             write            create           mkdir            
nid001472: 42        0%     91        1%     47        0%     0         0%     0         0%     
nid001472: symlink          mknod            remove           rmdir            rename           
nid001472: 0         0%     0         0%     0         0%     0         0%     0         0%     
nid001472: link             readdir          readdirplus      fsstat           fsinfo           
nid001472: 0         0%     0         0%     170       1%     0         0%     0         0%     
nid001472: pathconf         commit           
nid001472: 0         0%     0         0%     
nid001472: 
nid001472: 
nid001472: -----------------------------------------------------------------------------------
nid001472: 
nid001472: #### 2022-10-31.00 #### nid001472 - Job 17242461.cbqs01 NFS Mount Statistics for job duration (mountstats)
nid001472: ## /usr/sbin/mountstats iostat -S /tmp/mntstats.begin.17242461.cbqs01 /apps :
nid001472: 
nid001472: 
nid001472: 172.20.250.16:/AZ-HFS-Cactus-apps mounted on /apps:
nid001472: 
nid001472:            ops/s       rpc bklog
nid001472:            5.299           0.000
nid001472: 
nid001472: read:              ops/s            kB/s           kB/op         retrans    avg RTT (ms)    avg exe (ms)
nid001472:                    0.031           0.066           2.127        0 (0.0%)           0.370           0.435
nid001472: write:             ops/s            kB/s           kB/op         retrans    avg RTT (ms)    avg exe (ms)
nid001472:                    0.000           0.000           0.000        0 (0.0%)           0.000           0.000
nid001472: ## /usr/sbin/mountstats iostat -S /tmp/mntstats.begin.17242461.cbqs01 /sfs :
nid001472: 
nid001472: 
nid001472: 172.20.250.16:/AZ-HFS-Cactus-sfs mounted on /sfs:
nid001472: 
nid001472:            ops/s       rpc bklog
nid001472:            5.295           0.000
nid001472: 
nid001472: read:              ops/s            kB/s           kB/op         retrans    avg RTT (ms)    avg exe (ms)
nid001472:                    0.001           0.003           2.223        0 (0.0%)           0.500           0.500
nid001472: write:             ops/s            kB/s           kB/op         retrans    avg RTT (ms)    avg exe (ms)
nid001472:                    0.031           0.085           2.709        0 (0.0%)           1.489           1.596
nid001472: ## /usr/sbin/mountstats iostat -S /tmp/mntstats.begin.17242461.cbqs01 /u :
nid001472: 
nid001472: 
nid001472: 172.20.250.17:/AZ-HFS-Cactus-u mounted on /u:
nid001472: 
nid001472:            ops/s       rpc bklog
nid001472:            0.060           0.000
nid001472: 
nid001472: read:              ops/s            kB/s           kB/op         retrans    avg RTT (ms)    avg exe (ms)
nid001472:                    0.001           0.001           0.969        0 (0.0%)           0.000           0.000
nid001472: write:             ops/s            kB/s           kB/op         retrans    avg RTT (ms)    avg exe (ms)
nid001472:                    0.000           0.000           0.000        0 (0.0%)           0.000           0.000
nid001472: ## /usr/sbin/mountstats iostat -S /tmp/mntstats.begin.17242461.cbqs01 /pe :
nid001472: 
nid001472: 
nid001472: 10.31.62.244:/cm_shared/image/images_rw_nfs/pe mounted on /pe:
nid001472: 
nid001472:            ops/s       rpc bklog
nid001472:            0.788           0.000
nid001472: 
nid001472: read:              ops/s            kB/s           kB/op         retrans    avg RTT (ms)    avg exe (ms)
nid001472:                    0.003           0.097          28.980        0 (0.0%)           0.400           0.600
nid001472: write:             ops/s            kB/s           kB/op         retrans    avg RTT (ms)    avg exe (ms)
nid001472:                    0.000           0.000           0.000        0 (0.0%)           0.000           0.000
nid001472: ----------------
nid001472: ## /usr/sbin/mountstats mountstats -S /tmp/mntstats.begin.17242461.cbqs01 /apps :
nid001472: Stats for 172.20.250.16:/AZ-HFS-Cactus-apps mounted on /apps:
nid001472:   NFS mount options: ro,vers=3,rsize=65536,wsize=65536,namlen=255,acregmin=3,acregmax=60,acdirmin=30,acdirmax=60,hard,proto=tcp,timeo=600,retrans=2,sec=sys,mountaddr=172.20.250.16,mountvers=3,mountport=4048,mountproto=udp,local_lock=none
nid001472:   NFS server capabilities: caps=0x3fc7,wtmult=4096,dtsize=8192,bsize=0,namlen=255
nid001472:   NFS security flavor: 1  pseudoflavor: 0
nid001472: 
nid001472: NFS byte counts:
nid001472:   applications read 5811508 bytes via read(2)
nid001472:   applications wrote 0 bytes via write(2)
nid001472:   applications read 0 bytes via O_DIRECT read(2)
nid001472:   applications wrote 0 bytes via O_DIRECT write(2)
nid001472:   client read 86870 bytes via NFS READ
nid001472:   client wrote 0 bytes via NFS WRITE
nid001472: 
nid001472: RPC statistics:
nid001472:   7906 RPC requests sent, 7906 RPC replies received (0 XIDs not found)
nid001472:   average backlog queue length: 0
nid001472: 
nid001472: GETATTR:
nid001472: 	7120 ops (90%) 
nid001472: 	avg bytes sent per op: avg bytes received per op: 112
nid001472: 	backlog wait: 0.003090 	RTT: 0.191854 	total execute time: 0.209831 (milliseconds)
nid001472: ACCESS:
nid001472: 	246 ops (3%) 
nid001472: 	avg bytes sent per op: avg bytes received per op: 120
nid001472: 	backlog wait: 0.004065 	RTT: 0.325203 	total execute time: 0.345528 (milliseconds)
nid001472: READDIRPLUS:
nid001472: 	170 ops (2%) 
nid001472: 	avg bytes sent per op: avg bytes received per op: 933
nid001472: 	backlog wait: 0.000000 	RTT: 0.182353 	total execute time: 0.200000 (milliseconds)
nid001472: LOOKUP:
nid001472: 	137 ops (1%) 
nid001472: 	avg bytes sent per op: avg bytes received per op: 160
nid001472: 	backlog wait: 0.007299 	RTT: 0.145985 	total execute time: 0.167883 (milliseconds)
nid001472: READ:
nid001472: 	46 ops (0%) 
nid001472: 	avg bytes sent per op: avg bytes received per op: 2018
nid001472: 	backlog wait: 0.043478 	RTT: 0.369565 	total execute time: 0.434783 (milliseconds)
nid001472: READLINK:
nid001472: 	40 ops (0%) 
nid001472: 	avg bytes sent per op: avg bytes received per op: 132
nid001472: 	backlog wait: 0.000000 	RTT: 0.100000 	total execute time: 0.125000 (milliseconds)
nid001472: 
nid001472: ## /usr/sbin/mountstats mountstats -S /tmp/mntstats.begin.17242461.cbqs01 /sfs :
nid001472: 
nid001472: Stats for 172.20.250.16:/AZ-HFS-Cactus-sfs mounted on /sfs:
nid001472:   NFS mount options: rw,vers=3,rsize=65536,wsize=65536,namlen=255,acregmin=3,acregmax=60,acdirmin=30,acdirmax=60,hard,proto=tcp,timeo=600,retrans=2,sec=sys,mountaddr=172.20.250.16,mountvers=3,mountport=4048,mountproto=udp,local_lock=none
nid001472:   NFS server capabilities: caps=0x3fc7,wtmult=4096,dtsize=8192,bsize=0,namlen=255
nid001472:   NFS security flavor: 1  pseudoflavor: 0
nid001472: 
nid001472: NFS byte counts:
nid001472:   applications read 13847 bytes via read(2)
nid001472:   applications wrote 21740 bytes via write(2)
nid001472:   applications read 0 bytes via O_DIRECT read(2)
nid001472:   applications wrote 0 bytes via O_DIRECT write(2)
nid001472:   client read 4040 bytes via NFS READ
nid001472:   client wrote 116403 bytes via NFS WRITE
nid001472: 
nid001472: RPC statistics:
nid001472:   7906 RPC requests sent, 7906 RPC replies received (0 XIDs not found)
nid001472:   average backlog queue length: 0
nid001472: 
nid001472: GETATTR:
nid001472: 	85 ops (1%) 
nid001472: 	avg bytes sent per op: avg bytes received per op: 112
nid001472: 	backlog wait: 0.000000 	RTT: 0.164706 	total execute time: 0.200000 (milliseconds)
nid001472: WRITE:
nid001472: 	47 ops (0%) 
nid001472: 	avg bytes sent per op: avg bytes received per op: 160
nid001472: 	backlog wait: 0.042553 	RTT: 1.489362 	total execute time: 1.595745 (milliseconds)
nid001472: ACCESS:
nid001472: 	6 ops (0%) 
nid001472: 	avg bytes sent per op: avg bytes received per op: 120
nid001472: 	backlog wait: 0.000000 	RTT: 0.333333 	total execute time: 0.333333 (milliseconds)
nid001472: LOOKUP:
nid001472: 	5 ops (0%) 
nid001472: 	avg bytes sent per op: avg bytes received per op: 240
nid001472: 	backlog wait: 0.000000 	RTT: 0.200000 	total execute time: 0.400000 (milliseconds)
nid001472: SETATTR:
nid001472: 	2 ops (0%) 
nid001472: 	avg bytes sent per op: avg bytes received per op: 144
nid001472: 	backlog wait: 0.000000 	RTT: 0.500000 	total execute time: 1.000000 (milliseconds)
nid001472: READ:
nid001472: 	2 ops (0%) 
nid001472: 	avg bytes sent per op: avg bytes received per op: 2150
nid001472: 	backlog wait: 0.000000 	RTT: 0.500000 	total execute time: 0.500000 (milliseconds)
nid001472: 
nid001472: ## /usr/sbin/mountstats mountstats -S /tmp/mntstats.begin.17242461.cbqs01 /u :
nid001472: 
nid001472: Stats for 172.20.250.17:/AZ-HFS-Cactus-u mounted on /u:
nid001472:   NFS mount options: rw,vers=3,rsize=65536,wsize=65536,namlen=255,acregmin=3,acregmax=60,acdirmin=30,acdirmax=60,hard,proto=tcp,timeo=600,retrans=2,sec=sys,mountaddr=172.20.250.17,mountvers=3,mountport=4048,mountproto=udp,local_lock=none
nid001472:   NFS server capabilities: caps=0x3fc7,wtmult=4096,dtsize=8192,bsize=0,namlen=255
nid001472:   NFS security flavor: 1  pseudoflavor: 0
nid001472: 
nid001472: NFS byte counts:
nid001472:   applications read 701 bytes via read(2)
nid001472:   applications wrote 0 bytes via write(2)
nid001472:   applications read 0 bytes via O_DIRECT read(2)
nid001472:   applications wrote 0 bytes via O_DIRECT write(2)
nid001472:   client read 701 bytes via NFS READ
nid001472:   client wrote 0 bytes via NFS WRITE
nid001472: 
nid001472: RPC statistics:
nid001472:   89 RPC requests sent, 89 RPC replies received (0 XIDs not found)
nid001472:   average backlog queue length: 0
nid001472: 
nid001472: GETATTR:
nid001472: 	48 ops (53%) 
nid001472: 	avg bytes sent per op: avg bytes received per op: 112
nid001472: 	backlog wait: 0.020833 	RTT: 0.270833 	total execute time: 0.291667 (milliseconds)
nid001472: ACCESS:
nid001472: 	28 ops (31%) 
nid001472: 	avg bytes sent per op: avg bytes received per op: 120
nid001472: 	backlog wait: 0.000000 	RTT: 0.142857 	total execute time: 0.178571 (milliseconds)
nid001472: LOOKUP:
nid001472: 	12 ops (13%) 
nid001472: 	avg bytes sent per op: avg bytes received per op: 136
nid001472: 	backlog wait: 0.000000 	RTT: 0.083333 	total execute time: 0.333333 (milliseconds)
nid001472: READ:
nid001472: 	1 ops (1%) 
nid001472: 	avg bytes sent per op: avg bytes received per op: 832
nid001472: 	backlog wait: 0.000000 	RTT: 0.000000 	total execute time: 0.000000 (milliseconds)
nid001472: 
nid001472: ## /usr/sbin/mountstats mountstats -S /tmp/mntstats.begin.17242461.cbqs01 /pe :
nid001472: 
nid001472: Stats for 10.31.62.244:/cm_shared/image/images_rw_nfs/pe mounted on /pe:
nid001472:   NFS mount options: ro,vers=3,rsize=1048576,wsize=1048576,namlen=255,acregmin=3,acregmax=60,acdirmin=30,acdirmax=60,hard,nolock,proto=tcp,timeo=600,retrans=2,sec=sys,mountaddr=10.31.62.244,mountvers=3,mountport=38465,mountproto=tcp,local_lock=all
nid001472:   NFS server capabilities: caps=0x3fcf,wtmult=4096,dtsize=32768,bsize=0,namlen=255
nid001472:   NFS security flavor: 1  pseudoflavor: 0
nid001472: 
nid001472: NFS byte counts:
nid001472:   applications read 9216 bytes via read(2)
nid001472:   applications wrote 0 bytes via write(2)
nid001472:   applications read 0 bytes via O_DIRECT read(2)
nid001472:   applications wrote 0 bytes via O_DIRECT write(2)
nid001472:   client read 147456 bytes via NFS READ
nid001472:   client wrote 0 bytes via NFS WRITE
nid001472: 
nid001472: RPC statistics:
nid001472:   1175 RPC requests sent, 1176 RPC replies received (0 XIDs not found)
nid001472:   average backlog queue length: 0
nid001472: 
nid001472: GETATTR:
nid001472: 	831 ops (70%) 
nid001472: 	avg bytes sent per op: avg bytes received per op: 112
nid001472: 	backlog wait: 0.002407 	RTT: 0.358604 	total execute time: 0.376655 (milliseconds)
nid001472: LOOKUP:
nid001472: 	159 ops (13%) 
nid001472: 	avg bytes sent per op: avg bytes received per op: 82
nid001472: 	backlog wait: 0.000000 	RTT: 0.584906 	total execute time: 0.597484 (milliseconds)
nid001472: ACCESS:
nid001472: 	34 ops (2%) 
nid001472: 	avg bytes sent per op: avg bytes received per op: 36
nid001472: 	backlog wait: 0.000000 	RTT: 0.323529 	total execute time: 0.352941 (milliseconds)
nid001472: READ:
nid001472: 	5 ops (0%) 
nid001472: 	avg bytes sent per op: avg bytes received per op: 29535
nid001472: 	backlog wait: 0.000000 	RTT: 0.400000 	total execute time: 0.600000 (milliseconds)
nid001472: READLINK:
nid001472: 	2 ops (0%) 
nid001472: 	avg bytes sent per op: avg bytes received per op: 136
nid001472: 	backlog wait: 0.000000 	RTT: 0.500000 	total execute time: 0.000000 (milliseconds)
nid001472: 
nid001472: 

------------------------------------------------------------------
### Job 17242461.cbqs01 - Exit status is 0

------------------------------------------------------------------
Job 17242461.cbqs01 - Job summary:
Job Id: 17242461.cbqs01
    Job_Name = run_urma_stats
    Job_Owner = perry.shafran@clogin05.cactus.wcoss2.ncep.noaa.gov
    resources_used.cpupercent = 2
    resources_used.cput = 00:00:02
    resources_used.mem = 14316kb
    resources_used.ncpus = 1
    resources_used.vmem = 46000kb
    resources_used.walltime = 00:24:08
    job_state = R
    queue = dev
    server = cbqs01
    Account_Name = VERF-DEV
    Checkpoint = u
    ctime = Mon Oct 31 14:07:10 2022
    Error_Path = clogin05.cactus.wcoss2.ncep.noaa.gov:/lfs/h2/emc/vpppg/save/pe
	rry.shafran/EVS/ecf/realtime_analyses/stats/run_urma_stats.e17242461
    exec_host = nid001472/0
    exec_vnode = (nid001472:ncpus=1:mem=2097152kb)
    Hold_Types = n
    Join_Path = oe
    Keep_Files = oed
    Mail_Points = a
    mtime = Mon Oct 31 14:31:23 2022
    Output_Path = clogin05.cactus.wcoss2.ncep.noaa.gov:/lfs/h2/emc/vpppg/save/p
	erry.shafran/EVS/ecf/realtime_analyses/stats/run_urma_stats.o17242461
    Priority = 0
    qtime = Mon Oct 31 14:07:10 2022
    Rerunable = False
    Resource_List.alvl = 2
    Resource_List.aslr = True
    Resource_List.debug = True
    Resource_List.dfs = False
    Resource_List.hyper = False
    Resource_List.mem = 2gb
    Resource_List.ncpus = 1
    Resource_List.nodect = 1
    Resource_List.one-shot = False
    Resource_List.place = shared
    Resource_List.select = 1:ncpus=1:mem=2GB
    Resource_List.thp = True
    Resource_List.turbo = True
    Resource_List.walltime = 02:00:00
    schedselect = 1:ncpus=1:mem=2GB:prepost=False
    stime = Mon Oct 31 14:07:11 2022
    session_id = 94039
    Shell_Path_List = /bin/bash
    jobdir = /u/perry.shafran
    substate = 42
    Variable_List = PBS_O_HOME=/u/perry.shafran,PBS_O_LANG=en_US.UTF-8,
	PBS_O_LOGNAME=perry.shafran,
	PBS_O_PATH=/apps/ops/prod/nco/core/prod_util.v2.0.14/ush:/apps/prod/hp
	c-stack/intel-19.1.3.304/netcdf/4.7.4/bin:/apps/prod/hpc-stack/intel-19
	.1.3.304/hdf5/1.10.6/bin:/apps/spack/python/3.8.6/intel/19.1.3.304/pjn2
	nzkjvqgmjw4hmyz43v5x4jbxjzpk/bin:/apps/ops/para/libs/intel/19.1.3.304/m
	etplus/4.1.1/ush:/apps/ops/para/libs/intel/19.1.3.304/met/10.1.1/bin:/a
	pps/ops/para/libs/intel/19.1.3.304/gsl/2.6/bin:/pe/intel/compilers_and_
	libraries_2020.4.304/linux/bin/intel64:/pe/intel/compilers_and_librarie
	s_2020.4.304/linux/bin:/pe/intel/compilers_and_libraries_2020.4.304/lin
	ux/mpi/intel64/bin:/pe/intel/debugger_2020/gdb/intel64/bin:/opt/cray/li
	bfabric/1.11.0.0./bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt
	/sgi/bin:/usr/local/bin:/usr/bin:/bin:/usr/lib/mit/bin:/usr/lib/mit/sbi
	n:/opt/pbs/bin:/sbin:.:/u/perry.shafran/bin:/usr/sbin:/apps/prod/python
	-modules/3.8.6/intel/19.1.3.304/bin:/apps/prod/python-modules/3.8.6/int
	el/19.1.3.304/lib/python3.8/site-packages/bin,
	PBS_O_MAIL=/var/spool/mail/perry.shafran,PBS_O_SHELL=/bin/bash,
	PBS_O_WORKDIR=/lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_an
	alyses/stats,PBS_O_SYSTEM=Linux,PBS_O_QUEUE=dev,
	PBS_O_HOST=clogin05.cactus.wcoss2.ncep.noaa.gov
    euser = perry.shafran
    egroup = emc
    hashname = 17242461.cbqs01
    queue_rank = 1667225230589
    queue_type = E
    comment = Job run at Mon Oct 31 at 14:07 on (nid001472:ncpus=1:mem=2097152k
	b)
    etime = Mon Oct 31 14:07:10 2022
    umask = 22
    run_count = 6
    eligible_time = 00:00:00
    accrue_type = 3
    Submit_arguments = run_urma_stats.sh
    project = VERF-DEV
    run_version = 1
    Submit_Host = clogin05.cactus.wcoss2.ncep.noaa.gov


------------------------------------------------------------------
Job 17242461.cbqs01 - PBS tracejob output (for parent mom node only):

Job: 17242461.cbqs01

10/31/2022 14:07:11  M    update_job_usage: CPU usage: 0.000 secs
10/31/2022 14:07:11  M    update_job_usage: cpupercent initialized to zero
10/31/2022 14:07:11  M    update_job_usage: Memory usage: mem=0b
10/31/2022 14:07:11  M    no active tasks
10/31/2022 14:07:14  M    Started, pid = 94039
10/31/2022 14:08:06  M    update_job_usage: CPU usage: 1.564 secs
10/31/2022 14:08:06  M    update_job_usage: 17242461.cbqs01 measured interval cpupercent 2 increased job cpupercent to 2
10/31/2022 14:08:06  M    update_job_usage: Memory usage: mem=14316kb
10/31/2022 14:10:07  M    update_job_usage: CPU usage: 1.589 secs
10/31/2022 14:10:07  M    update_job_usage: Memory usage: mem=14316kb
10/31/2022 14:12:08  M    update_job_usage: CPU usage: 1.612 secs
10/31/2022 14:12:08  M    update_job_usage: Memory usage: mem=14316kb
10/31/2022 14:14:09  M    update_job_usage: CPU usage: 1.637 secs
10/31/2022 14:14:09  M    update_job_usage: Memory usage: mem=14316kb
10/31/2022 14:16:11  M    update_job_usage: CPU usage: 1.662 secs
10/31/2022 14:16:11  M    update_job_usage: Memory usage: mem=14316kb
10/31/2022 14:18:12  M    update_job_usage: CPU usage: 1.687 secs
10/31/2022 14:18:12  M    update_job_usage: Memory usage: mem=14316kb
10/31/2022 14:20:13  M    update_job_usage: CPU usage: 1.710 secs
10/31/2022 14:20:13  M    update_job_usage: Memory usage: mem=14316kb
10/31/2022 14:22:14  M    update_job_usage: CPU usage: 1.734 secs
10/31/2022 14:22:14  M    update_job_usage: Memory usage: mem=14316kb
10/31/2022 14:24:15  M    update_job_usage: CPU usage: 1.758 secs
10/31/2022 14:24:15  M    update_job_usage: Memory usage: mem=14316kb
10/31/2022 14:26:16  M    update_job_usage: CPU usage: 1.785 secs
10/31/2022 14:26:16  M    update_job_usage: Memory usage: mem=14316kb
10/31/2022 14:28:18  M    update_job_usage: CPU usage: 1.809 secs
10/31/2022 14:28:18  M    update_job_usage: Memory usage: mem=14316kb
10/31/2022 14:30:19  M    update_job_usage: CPU usage: 1.834 secs
10/31/2022 14:30:19  M    update_job_usage: Memory usage: mem=14316kb
10/31/2022 14:32:06  M    task 00000001 terminated
10/31/2022 14:32:06  M    Terminated
10/31/2022 14:32:06  M    task 00000001 cput=00:00:03
10/31/2022 14:32:06  M    kill_job
10/31/2022 14:32:06  M    nid001472 cput=00:00:02 mem=14316kb
10/31/2022 14:32:06  M    update_job_usage: CPU usage: 1.848 secs
10/31/2022 14:32:06  M    update_job_usage: Memory usage: mem=14316kb

------------------------------------------------------------------
To see full PBS log data, run: /sfs/admin/scripts/tracejob.sh 17242461.cbqs01

==================================================================
END - DEBUG INFO
==================================================================

##### Job 17242461.cbqs01 - PBS Job Script:

#PBS -N run_urma_stats
#PBS -N run_urma_stats
#PBS -j oe
#PBS -j oe
#PBS -S /bin/bash
#PBS -S /bin/bash
#PBS -q "dev"
#PBS -q "dev"
#PBS -A VERF-DEV
#PBS -A VERF-DEV
#PBS -l walltime=02:00:00
#PBS -l walltime=02:00:00
#PBS -l select=1:ncpus=1:mem=2GB
#PBS -l select=1:ncpus=1:mem=2GB
#PBS -l debug=true
#PBS -l debug=true

set -x

for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
do
   export fhr
   qsub -v cyc=$fhr /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
   sleep 60
done

exit

##### End of job script
------------------------------------------------------------------
