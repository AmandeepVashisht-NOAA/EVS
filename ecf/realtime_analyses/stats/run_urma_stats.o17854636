Running prologue on parent mom node: nid001093...
Job 17854636.cbqs01 nodelist: nid001093
Job 17854636.cbqs01 - Prologue complete. Execution time: 3 seconds
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=00 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17854640.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=01 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17854753.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=02 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17854865.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=03 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17854886.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=04 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17854927.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=05 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17854990.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=06 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17855063.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=07 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17855158.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=08 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17855201.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=09 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17855322.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=10 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17855352.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=11 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17855446.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=12 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17855513.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=13 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17855565.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=14 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17855634.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=15 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17855656.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=16 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17855714.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=17 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17855772.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=18 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17855783.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=19 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17855824.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=20 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17855885.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=21 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17856030.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=22 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17856076.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=23 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
17856120.cbqs01
++ sleep 60
++ exit
Job 17854636.cbqs01 - Epilogue complete. Execution time: 1 seconds
==================================================================
BEGIN - DEBUG INFO
==================================================================
Job 17854636.cbqs01 - Post Job Mem Usage:
nid001093: 2022-11-04.14 1 ===========================================
nid001093: 2022-11-04.14 2 #### Node Memory Usage for nid001093 ####
nid001093: 2022-11-04.14 3 ------------------
nid001093: 2022-11-04.14 4 Mem: total:527077116 used:11172164 free:509079580 shared:4802388 cache:6825372 avail:508859852
nid001093: 2022-11-04.14 5 4.0K	/dev/shm
nid001093: 2022-11-04.14 6 30M	/tmp
nid001093: 2022-11-04.14 7 ===========================================
nid001093: 2022-11-04.27 1 ===========================================
nid001093: 2022-11-04.27 2 #### Node Memory Usage for nid001093 ####
nid001093: 2022-11-04.27 3 ------------------
nid001093: 2022-11-04.27 4 Mem: total:527077116 used:11144368 free:509041992 shared:4801932 cache:6890756 avail:508866120
nid001093: 2022-11-04.27 5 4.0K	/dev/shm
nid001093: 2022-11-04.27 6 30M	/tmp
nid001093: 2022-11-04.27 7 ===========================================

------------------------------------------------------------------
Job 17854636.cbqs01 - /var/log/messages for job duration:
nid001093: 2022-11-04A--:--:--.------+--:-- nid001093 #### nid001093 - Job 17854636.cbqs01 Runtime Data from /var/log/messages
nid001093: 2022-11-04T18:29:12.898619+00:00 nid001093 prologue: MARK: Job 17854636.cbqs01 Start
nid001093: 2022-11-04T18:29:12.903520+00:00 nid001093 prologue: Job 17854636.cbqs01 nodelist: nid001093
nid001093: 2022-11-04T18:29:12.904615+00:00 nid001093 prologue: Job 17854636.cbqs01 - Checking existing ASLR settings...
nid001093: 2022-11-04T18:29:12.909187+00:00 nid001093 prologue: Job 17854636.cbqs01 - Checking palsd open file count...
nid001093: 2022-11-04T18:29:13.017105+00:00 nid001093 PBS_CMD: root : /opt/pbs/bin/qstat -Bf
nid001093: 2022-11-04T18:29:14.050041+00:00 nid001093 prologue: Job 17854636.cbqs01 - Checking one-shot control: False
nid001093: 2022-11-04T18:29:14.051115+00:00 nid001093 prologue: Job 17854636.cbqs01 - Recording pre-job HSN counters...
nid001093: 2022-11-04T18:29:14.161816+00:00 nid001093 prologue: Job 17854636.cbqs01 - Recording pre-job memory usage...
nid001093: 2022-11-04T18:29:14.249193+00:00 nid001093 prologue: Job 17854636.cbqs01 - Killing any stray user processes...
nid001093: 2022-11-04T18:29:14.325379+00:00 nid001093 prologue: Job 17854636.cbqs01 - Enabling turboboost...
nid001093: 2022-11-04T18:29:14.327926+00:00 nid001093 prologue: Job 17854636.cbqs01 - Verifying post-boot workarounds...
nid001093: 2022-11-04T18:29:14.650095+00:00 nid001093 prologue: Job 17854636.cbqs01 - Warchk Complete
nid001093: 2022-11-04T18:29:14.651777+00:00 nid001093 prologue: Job 17854636.cbqs01 - Recording initial NFS client statistics...
nid001093: 2022-11-04T18:29:14.658123+00:00 nid001093 prologue: Job 17854636.cbqs01 - Prologue complete. Execution time: 3 seconds
nid001093: 2022-11-04T18:30:22.076842+00:00 nid001093 systemd[1]: etc_update.service: Succeeded.
nid001093: 2022-11-04T18:42:54.068481+00:00 nid001093 systemd[1]: etc_update.service: Succeeded.
nid001093: 2022-11-04T18:52:32.067651+00:00 nid001093 systemd[1]: etc_update.service: Succeeded.
nid001093: 2022-11-04T18:53:27.193191+00:00 nid001093 epilogue: Job 17854636.cbqs01 complete, running post-job actions.
nid001093: 2022-11-04T18:53:27.209923+00:00 nid001093 epilogue: Job 17854636.cbqs01 - Recording post-job HSN counters...
nid001093: 2022-11-04T18:53:27.321863+00:00 nid001093 epilogue: Job 17854636.cbqs01 - Recording post-job memory usage...
nid001093: 2022-11-04T18:53:27.341592+00:00 nid001093 epilogue: Job 17854636.cbqs01 - Recording job NFS statistics to /tmp/nfsstats.17854636.cbqs01
nid001093: 2022-11-04T18:53:27.824669+00:00 nid001093 epilogue: Job 17854636.cbqs01 - Clearing /tmp...
nid001093: 2022-11-04T18:53:27.848860+00:00 nid001093 epilogue: Job 17854636.cbqs01 - Clearing shared memory...
nid001093: 2022-11-04T18:53:27.860691+00:00 nid001093 epilogue: Job 17854636.cbqs01 - Clearing memory cache...
nid001093: 2022-11-04T18:53:28.237379+00:00 nid001093 kernel: [7969934.339889] drop_caches (52054): drop_caches: 3
nid001093: 2022-11-04T18:53:28.379100+00:00 nid001093 epilogue: Job 17854636.cbqs01 - Releasing Lustre Locks...
nid001093: 2022-11-04T18:53:28.496773+00:00 nid001093 epilogue: MARK: Job 17854636.cbqs01 Complete.

------------------------------------------------------------------
Job 17854636.cbqs01 - dmesg output for job duration:
nid001093: 2022-11-04A--:--:--.------+--:-- nid001093 #### nid001093 - Job 17854636.cbqs01 Runtime Data from dmesg
nid001093: [Fri Nov  4 18:26:19 2022] MARK: Job 17854636.cbqs01 Start
nid001093: [Fri Nov  4 18:50:34 2022] MARK: Job 17854636.cbqs01 Complete.
nid001093: [Fri Nov  4 18:50:34 2022] drop_caches (52054): drop_caches: 3

------------------------------------------------------------------
Job 17854636.cbqs01 - Pre/Post job diff on HSN (MLX) Counters:
nid001093: 2022-11-04A--:--:--.------+--:-- nid001093 #### nid001093 - Job 17854636.cbqs01 HSN0 MLX Counter Post-Job Difference
nid001093: multicast: 300395058					      |	multicast: 300395321
nid001093: port_rcv_data: 457522444473571				      |	port_rcv_data: 457522444799885
nid001093: port_rcv_packets: 916321114545				      |	port_rcv_packets: 916321121016
nid001093: port_xmit_data: 470253293182370				      |	port_xmit_data: 470253293525374
nid001093: port_xmit_packets: 934114339440				      |	port_xmit_packets: 934114345932
nid001093: rx_bytes: 1509446821015					      |	rx_bytes: 1509456272644
nid001093: rx_packets: 1614809379					      |	rx_packets: 1614819706
nid001093: tx_bytes: 1029543066520					      |	tx_bytes: 1029544326814
nid001093: tx_packets: 846558857					      |	tx_packets: 846565893
nid001093: unicast_rcv_packets: 916321114545			      |	unicast_rcv_packets: 916321121016
nid001093: unicast_xmit_packets: 934114339440			      |	unicast_xmit_packets: 934114345932

------------------------------------------------------------------
### Job 17854636.cbqs01 - NFS Statistics for job duration:
nid001093: #### 2022-11-04.00 #### nid001093 - Job 17854636.cbqs01 NFS Statistics for job duration (nfsstat)
nid001093: ## /usr/sbin/nfsstat -v -S /tmp/nfsstats.begin.17854636.cbqs01 :
nid001093: Client packet stats:
nid001093: packets    udp        tcp        tcpconn
nid001093: 0          0          0          0       
nid001093: 
nid001093: Client rpc stats:
nid001093: calls      retrans    authrefrsh
nid001093: 4713       0          4712    
nid001093: 
nid001093: Client nfs v3:
nid001093: null             getattr          setattr          lookup           access           
nid001093: 0         0%     3582     76%     3         0%     349       7%     319       6%     
nid001093: readlink         read             write            create           mkdir            
nid001093: 48        1%     252       5%     48        1%     0         0%     0         0%     
nid001093: symlink          mknod            remove           rmdir            rename           
nid001093: 0         0%     0         0%     0         0%     0         0%     0         0%     
nid001093: link             readdir          readdirplus      fsstat           fsinfo           
nid001093: 0         0%     0         0%     112       2%     0         0%     0         0%     
nid001093: pathconf         commit           
nid001093: 0         0%     0         0%     
nid001093: 
nid001093: 
nid001093: -----------------------------------------------------------------------------------
nid001093: 
nid001093: #### 2022-11-04.00 #### nid001093 - Job 17854636.cbqs01 NFS Mount Statistics for job duration (mountstats)
nid001093: ## /usr/sbin/mountstats iostat -S /tmp/mntstats.begin.17854636.cbqs01 /apps :
nid001093: 
nid001093: 
nid001093: 172.20.250.16:/AZ-HFS-Cactus-apps mounted on /apps:
nid001093: 
nid001093:            ops/s       rpc bklog
nid001093:            2.363           0.000
nid001093: 
nid001093: read:              ops/s            kB/s           kB/op         retrans    avg RTT (ms)    avg exe (ms)
nid001093:                    0.056           0.120           2.124        0 (0.0%)           0.195           0.244
nid001093: write:             ops/s            kB/s           kB/op         retrans    avg RTT (ms)    avg exe (ms)
nid001093:                    0.000           0.000           0.000        0 (0.0%)           0.000           0.000
nid001093: ## /usr/sbin/mountstats iostat -S /tmp/mntstats.begin.17854636.cbqs01 /sfs :
nid001093: 
nid001093: 
nid001093: 172.20.250.16:/AZ-HFS-Cactus-sfs mounted on /sfs:
nid001093: 
nid001093:            ops/s       rpc bklog
nid001093:            2.363           0.000
nid001093: 
nid001093: read:              ops/s            kB/s           kB/op         retrans    avg RTT (ms)    avg exe (ms)
nid001093:                    0.001           0.000           0.391        0 (0.0%)           0.000           0.000
nid001093: write:             ops/s            kB/s           kB/op         retrans    avg RTT (ms)    avg exe (ms)
nid001093:                    0.033           0.079           2.405        0 (0.0%)           1.771           1.854
nid001093: ## /usr/sbin/mountstats iostat -S /tmp/mntstats.begin.17854636.cbqs01 /u :
nid001093: 
nid001093: 
nid001093: 172.20.250.17:/AZ-HFS-Cactus-u mounted on /u:
nid001093: 
nid001093:            ops/s       rpc bklog
nid001093:            0.061           0.000
nid001093: 
nid001093: read:              ops/s            kB/s           kB/op         retrans    avg RTT (ms)    avg exe (ms)
nid001093:                    0.001           0.001           0.969        0 (0.0%)           0.000           0.000
nid001093: write:             ops/s            kB/s           kB/op         retrans    avg RTT (ms)    avg exe (ms)
nid001093:                    0.000           0.000           0.000        0 (0.0%)           0.000           0.000
nid001093: ## /usr/sbin/mountstats iostat -S /tmp/mntstats.begin.17854636.cbqs01 /pe :
nid001093: 
nid001093: 
nid001093: 10.31.62.243:/cm_shared/image/images_rw_nfs/pe mounted on /pe:
nid001093: 
nid001093:            ops/s       rpc bklog
nid001093:            0.894           0.000
nid001093: 
nid001093: read:              ops/s            kB/s           kB/op         retrans    avg RTT (ms)    avg exe (ms)
nid001093:                    0.022           1.808          82.055        0 (0.0%)           1.625           1.688
nid001093: write:             ops/s            kB/s           kB/op         retrans    avg RTT (ms)    avg exe (ms)
nid001093:                    0.000           0.000           0.000        0 (0.0%)           0.000           0.000
nid001093: ----------------
nid001093: ## /usr/sbin/mountstats mountstats -S /tmp/mntstats.begin.17854636.cbqs01 /apps :
nid001093: Stats for 172.20.250.16:/AZ-HFS-Cactus-apps mounted on /apps:
nid001093:   NFS mount options: ro,vers=3,rsize=65536,wsize=65536,namlen=255,acregmin=3,acregmax=60,acdirmin=30,acdirmax=60,hard,proto=tcp,timeo=600,retrans=2,sec=sys,mountaddr=172.20.250.16,mountvers=3,mountport=4048,mountproto=udp,local_lock=none
nid001093:   NFS server capabilities: caps=0x3fc7,wtmult=4096,dtsize=8192,bsize=0,namlen=255
nid001093:   NFS security flavor: 1  pseudoflavor: 0
nid001093: 
nid001093: NFS byte counts:
nid001093:   applications read 1346902 bytes via read(2)
nid001093:   applications wrote 0 bytes via write(2)
nid001093:   applications read 0 bytes via O_DIRECT read(2)
nid001093:   applications wrote 0 bytes via O_DIRECT write(2)
nid001093:   client read 154630 bytes via NFS READ
nid001093:   client wrote 0 bytes via NFS WRITE
nid001093: 
nid001093: RPC statistics:
nid001093:   3433 RPC requests sent, 3433 RPC replies received (0 XIDs not found)
nid001093:   average backlog queue length: 0
nid001093: 
nid001093: GETATTR:
nid001093: 	2619 ops (76%) 
nid001093: 	avg bytes sent per op: avg bytes received per op: 112
nid001093: 	backlog wait: 0.001909 	RTT: 0.088202 	total execute time: 0.098511 (milliseconds)
nid001093: ACCESS:
nid001093: 	251 ops (7%) 
nid001093: 	avg bytes sent per op: avg bytes received per op: 120
nid001093: 	backlog wait: 0.003984 	RTT: 0.270916 	total execute time: 0.282869 (milliseconds)
nid001093: LOOKUP:
nid001093: 	173 ops (5%) 
nid001093: 	avg bytes sent per op: avg bytes received per op: 164
nid001093: 	backlog wait: 0.005780 	RTT: 0.121387 	total execute time: 0.132948 (milliseconds)
nid001093: READDIRPLUS:
nid001093: 	112 ops (3%) 
nid001093: 	avg bytes sent per op: avg bytes received per op: 908
nid001093: 	backlog wait: 0.000000 	RTT: 0.098214 	total execute time: 0.107143 (milliseconds)
nid001093: READ:
nid001093: 	82 ops (2%) 
nid001093: 	avg bytes sent per op: avg bytes received per op: 2015
nid001093: 	backlog wait: 0.024390 	RTT: 0.195122 	total execute time: 0.243902 (milliseconds)
nid001093: READLINK:
nid001093: 	46 ops (1%) 
nid001093: 	avg bytes sent per op: avg bytes received per op: 135
nid001093: 	backlog wait: 0.000000 	RTT: 0.065217 	total execute time: 0.086957 (milliseconds)
nid001093: 
nid001093: ## /usr/sbin/mountstats mountstats -S /tmp/mntstats.begin.17854636.cbqs01 /sfs :
nid001093: 
nid001093: Stats for 172.20.250.16:/AZ-HFS-Cactus-sfs mounted on /sfs:
nid001093:   NFS mount options: rw,vers=3,rsize=65536,wsize=65536,namlen=255,acregmin=3,acregmax=60,acdirmin=30,acdirmax=60,hard,proto=tcp,timeo=600,retrans=2,sec=sys,mountaddr=172.20.250.16,mountvers=3,mountport=4048,mountproto=udp,local_lock=none
nid001093:   NFS server capabilities: caps=0x3fc7,wtmult=4096,dtsize=8192,bsize=0,namlen=255
nid001093:   NFS security flavor: 1  pseudoflavor: 0
nid001093: 
nid001093: NFS byte counts:
nid001093:   applications read 13993 bytes via read(2)
nid001093:   applications wrote 12071 bytes via write(2)
nid001093:   applications read 0 bytes via O_DIRECT read(2)
nid001093:   applications wrote 0 bytes via O_DIRECT write(2)
nid001093:   client read 146 bytes via NFS READ
nid001093:   client wrote 103922 bytes via NFS WRITE
nid001093: 
nid001093: RPC statistics:
nid001093:   3433 RPC requests sent, 3433 RPC replies received (0 XIDs not found)
nid001093:   average backlog queue length: 0
nid001093: 
nid001093: GETATTR:
nid001093: 	87 ops (2%) 
nid001093: 	avg bytes sent per op: avg bytes received per op: 112
nid001093: 	backlog wait: 0.011494 	RTT: 0.126437 	total execute time: 0.160920 (milliseconds)
nid001093: WRITE:
nid001093: 	48 ops (1%) 
nid001093: 	avg bytes sent per op: avg bytes received per op: 160
nid001093: 	backlog wait: 0.041667 	RTT: 1.770833 	total execute time: 1.854167 (milliseconds)
nid001093: ACCESS:
nid001093: 	6 ops (0%) 
nid001093: 	avg bytes sent per op: avg bytes received per op: 120
nid001093: 	backlog wait: 0.166667 	RTT: 0.333333 	total execute time: 0.333333 (milliseconds)
nid001093: LOOKUP:
nid001093: 	5 ops (0%) 
nid001093: 	avg bytes sent per op: avg bytes received per op: 240
nid001093: 	backlog wait: 0.000000 	RTT: 0.200000 	total execute time: 0.200000 (milliseconds)
nid001093: SETATTR:
nid001093: 	3 ops (0%) 
nid001093: 	avg bytes sent per op: avg bytes received per op: 144
nid001093: 	backlog wait: 0.000000 	RTT: 0.333333 	total execute time: 0.666667 (milliseconds)
nid001093: READ:
nid001093: 	1 ops (0%) 
nid001093: 	avg bytes sent per op: avg bytes received per op: 276
nid001093: 	backlog wait: 0.000000 	RTT: 0.000000 	total execute time: 0.000000 (milliseconds)
nid001093: 
nid001093: ## /usr/sbin/mountstats mountstats -S /tmp/mntstats.begin.17854636.cbqs01 /u :
nid001093: 
nid001093: Stats for 172.20.250.17:/AZ-HFS-Cactus-u mounted on /u:
nid001093:   NFS mount options: rw,vers=3,rsize=65536,wsize=65536,namlen=255,acregmin=3,acregmax=60,acdirmin=30,acdirmax=60,hard,proto=tcp,timeo=600,retrans=2,sec=sys,mountaddr=172.20.250.17,mountvers=3,mountport=4048,mountproto=udp,local_lock=none
nid001093:   NFS server capabilities: caps=0x3fc7,wtmult=4096,dtsize=8192,bsize=0,namlen=255
nid001093:   NFS security flavor: 1  pseudoflavor: 0
nid001093: 
nid001093: NFS byte counts:
nid001093:   applications read 701 bytes via read(2)
nid001093:   applications wrote 0 bytes via write(2)
nid001093:   applications read 0 bytes via O_DIRECT read(2)
nid001093:   applications wrote 0 bytes via O_DIRECT write(2)
nid001093:   client read 701 bytes via NFS READ
nid001093:   client wrote 0 bytes via NFS WRITE
nid001093: 
nid001093: RPC statistics:
nid001093:   89 RPC requests sent, 89 RPC replies received (0 XIDs not found)
nid001093:   average backlog queue length: 0
nid001093: 
nid001093: GETATTR:
nid001093: 	48 ops (53%) 
nid001093: 	avg bytes sent per op: avg bytes received per op: 112
nid001093: 	backlog wait: 0.020833 	RTT: 0.270833 	total execute time: 0.270833 (milliseconds)
nid001093: ACCESS:
nid001093: 	28 ops (31%) 
nid001093: 	avg bytes sent per op: avg bytes received per op: 120
nid001093: 	backlog wait: 0.000000 	RTT: 0.107143 	total execute time: 0.142857 (milliseconds)
nid001093: LOOKUP:
nid001093: 	12 ops (13%) 
nid001093: 	avg bytes sent per op: avg bytes received per op: 136
nid001093: 	backlog wait: 0.000000 	RTT: 0.166667 	total execute time: 0.083333 (milliseconds)
nid001093: READ:
nid001093: 	1 ops (1%) 
nid001093: 	avg bytes sent per op: avg bytes received per op: 832
nid001093: 	backlog wait: 0.000000 	RTT: 0.000000 	total execute time: 0.000000 (milliseconds)
nid001093: 
nid001093: ## /usr/sbin/mountstats mountstats -S /tmp/mntstats.begin.17854636.cbqs01 /pe :
nid001093: 
nid001093: Stats for 10.31.62.243:/cm_shared/image/images_rw_nfs/pe mounted on /pe:
nid001093:   NFS mount options: ro,vers=3,rsize=1048576,wsize=1048576,namlen=255,acregmin=3,acregmax=60,acdirmin=30,acdirmax=60,hard,nolock,proto=tcp,timeo=600,retrans=2,sec=sys,mountaddr=10.31.62.243,mountvers=3,mountport=38465,mountproto=tcp,local_lock=all
nid001093:   NFS server capabilities: caps=0x3fcf,wtmult=4096,dtsize=32768,bsize=0,namlen=255
nid001093:   NFS security flavor: 1  pseudoflavor: 0
nid001093: 
nid001093: NFS byte counts:
nid001093:   applications read 443392 bytes via read(2)
nid001093:   applications wrote 0 bytes via write(2)
nid001093:   applications read 0 bytes via O_DIRECT read(2)
nid001093:   applications wrote 0 bytes via O_DIRECT write(2)
nid001093:   client read 2682880 bytes via NFS READ
nid001093:   client wrote 0 bytes via NFS WRITE
nid001093: 
nid001093: RPC statistics:
nid001093:   1298 RPC requests sent, 1298 RPC replies received (0 XIDs not found)
nid001093:   average backlog queue length: 0
nid001093: 
nid001093: GETATTR:
nid001093: 	828 ops (63%) 
nid001093: 	avg bytes sent per op: avg bytes received per op: 112
nid001093: 	backlog wait: 0.001208 	RTT: 0.332126 	total execute time: 0.342995 (milliseconds)
nid001093: LOOKUP:
nid001093: 	159 ops (12%) 
nid001093: 	avg bytes sent per op: avg bytes received per op: 82
nid001093: 	backlog wait: 0.006289 	RTT: 0.584906 	total execute time: 0.597484 (milliseconds)
nid001093: ACCESS:
nid001093: 	34 ops (2%) 
nid001093: 	avg bytes sent per op: avg bytes received per op: 36
nid001093: 	backlog wait: 0.000000 	RTT: 0.323529 	total execute time: 0.323529 (milliseconds)
nid001093: READ:
nid001093: 	32 ops (2%) 
nid001093: 	avg bytes sent per op: avg bytes received per op: 83884
nid001093: 	backlog wait: 0.031250 	RTT: 1.625000 	total execute time: 1.687500 (milliseconds)
nid001093: READLINK:
nid001093: 	2 ops (0%) 
nid001093: 	avg bytes sent per op: avg bytes received per op: 136
nid001093: 	backlog wait: 0.000000 	RTT: 0.000000 	total execute time: 0.500000 (milliseconds)
nid001093: 
nid001093: 

------------------------------------------------------------------
### Job 17854636.cbqs01 - Exit status is 0

------------------------------------------------------------------
Job 17854636.cbqs01 - Job summary:
Job Id: 17854636.cbqs01
    Job_Name = run_urma_stats
    Job_Owner = perry.shafran@clogin01.cactus.wcoss2.ncep.noaa.gov
    resources_used.cpupercent = 10
    resources_used.cput = 00:00:02
    resources_used.mem = 23596kb
    resources_used.ncpus = 1
    resources_used.vmem = 39380kb
    resources_used.walltime = 00:24:09
    job_state = R
    queue = dev
    server = cbqs01
    Account_Name = VERF-DEV
    Checkpoint = u
    ctime = Fri Nov  4 18:29:10 2022
    Error_Path = clogin01.cactus.wcoss2.ncep.noaa.gov:/lfs/h2/emc/vpppg/save/pe
	rry.shafran/EVS/ecf/realtime_analyses/stats/run_urma_stats.e17854636
    exec_host = nid001093/0
    exec_vnode = (nid001093:ncpus=1:mem=2097152kb)
    Hold_Types = n
    Join_Path = oe
    Keep_Files = oed
    Mail_Points = a
    mtime = Fri Nov  4 18:53:23 2022
    Output_Path = clogin01.cactus.wcoss2.ncep.noaa.gov:/lfs/h2/emc/vpppg/save/p
	erry.shafran/EVS/ecf/realtime_analyses/stats/run_urma_stats.o17854636
    Priority = 0
    qtime = Fri Nov  4 18:29:10 2022
    Rerunable = False
    Resource_List.alvl = 2
    Resource_List.aslr = True
    Resource_List.debug = True
    Resource_List.dfs = False
    Resource_List.hyper = False
    Resource_List.mem = 2gb
    Resource_List.ncpus = 1
    Resource_List.nodect = 1
    Resource_List.one-shot = False
    Resource_List.place = shared
    Resource_List.select = 1:ncpus=1:mem=2GB
    Resource_List.thp = True
    Resource_List.turbo = True
    Resource_List.walltime = 02:00:00
    schedselect = 1:ncpus=1:mem=2GB:prepost=False
    stime = Fri Nov  4 18:29:11 2022
    session_id = 51043
    Shell_Path_List = /bin/bash
    jobdir = /u/perry.shafran
    substate = 42
    Variable_List = PBS_O_HOME=/u/perry.shafran,PBS_O_LANG=en_US.UTF-8,
	PBS_O_LOGNAME=perry.shafran,
	PBS_O_PATH=/apps/ops/prod/nco/core/prod_util.v2.0.14/ush:/apps/prod/hp
	c-stack/intel-19.1.3.304/netcdf/4.7.4/bin:/apps/prod/hpc-stack/intel-19
	.1.3.304/hdf5/1.10.6/bin:/apps/spack/python/3.8.6/intel/19.1.3.304/pjn2
	nzkjvqgmjw4hmyz43v5x4jbxjzpk/bin:/apps/ops/para/libs/intel/19.1.3.304/m
	etplus/4.1.1/ush:/apps/ops/para/libs/intel/19.1.3.304/met/10.1.1/bin:/a
	pps/ops/para/libs/intel/19.1.3.304/gsl/2.6/bin:/pe/intel/compilers_and_
	libraries_2020.4.304/linux/bin/intel64:/pe/intel/compilers_and_librarie
	s_2020.4.304/linux/bin:/pe/intel/compilers_and_libraries_2020.4.304/lin
	ux/mpi/intel64/bin:/pe/intel/debugger_2020/gdb/intel64/bin:/opt/cray/li
	bfabric/1.11.0.0./bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt
	/sgi/bin:/usr/local/bin:/usr/bin:/bin:/usr/lib/mit/bin:/usr/lib/mit/sbi
	n:/opt/pbs/bin:/sbin:.:/u/perry.shafran/bin:/usr/sbin:/apps/prod/python
	-modules/3.8.6/intel/19.1.3.304/bin:/apps/prod/python-modules/3.8.6/int
	el/19.1.3.304/lib/python3.8/site-packages/bin,
	PBS_O_MAIL=/var/spool/mail/perry.shafran,PBS_O_SHELL=/bin/bash,
	PBS_O_WORKDIR=/lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_an
	alyses/stats,PBS_O_SYSTEM=Linux,PBS_O_QUEUE=dev,
	PBS_O_HOST=clogin01.cactus.wcoss2.ncep.noaa.gov
    euser = perry.shafran
    egroup = emc
    hashname = 17854636.cbqs01
    queue_rank = 1667586550470
    queue_type = E
    comment = Job run at Fri Nov 04 at 18:29 on (nid001093:ncpus=1:mem=2097152k
	b)
    etime = Fri Nov  4 18:29:10 2022
    umask = 22
    run_count = 6
    eligible_time = 00:00:00
    accrue_type = 3
    Submit_arguments = run_urma_stats.sh
    project = VERF-DEV
    run_version = 1
    Submit_Host = clogin01.cactus.wcoss2.ncep.noaa.gov


------------------------------------------------------------------
Job 17854636.cbqs01 - PBS tracejob output (for parent mom node only):

Job: 17854636.cbqs01

11/04/2022 18:29:11  M    update_job_usage: CPU usage: 0.000 secs
11/04/2022 18:29:11  M    update_job_usage: cpupercent initialized to zero
11/04/2022 18:29:11  M    update_job_usage: Memory usage: mem=0b
11/04/2022 18:29:11  M    no active tasks
11/04/2022 18:29:14  M    Started, pid = 51043
11/04/2022 18:29:28  M    update_job_usage: CPU usage: 1.652 secs
11/04/2022 18:29:28  M    update_job_usage: 17854636.cbqs01 measured interval cpupercent 10 increased job cpupercent to 10
11/04/2022 18:29:28  M    update_job_usage: Memory usage: mem=23596kb
11/04/2022 18:31:29  M    update_job_usage: CPU usage: 1.675 secs
11/04/2022 18:31:29  M    update_job_usage: Memory usage: mem=23596kb
11/04/2022 18:33:30  M    update_job_usage: CPU usage: 1.697 secs
11/04/2022 18:33:30  M    update_job_usage: Memory usage: mem=23596kb
11/04/2022 18:35:31  M    update_job_usage: CPU usage: 1.720 secs
11/04/2022 18:35:31  M    update_job_usage: Memory usage: mem=23596kb
11/04/2022 18:37:32  M    update_job_usage: CPU usage: 1.742 secs
11/04/2022 18:37:32  M    update_job_usage: Memory usage: mem=23596kb
11/04/2022 18:39:34  M    update_job_usage: CPU usage: 1.762 secs
11/04/2022 18:39:34  M    update_job_usage: Memory usage: mem=23596kb
11/04/2022 18:41:35  M    update_job_usage: CPU usage: 1.784 secs
11/04/2022 18:41:35  M    update_job_usage: Memory usage: mem=23596kb
11/04/2022 18:43:37  M    update_job_usage: CPU usage: 1.806 secs
11/04/2022 18:43:37  M    update_job_usage: Memory usage: mem=23596kb
11/04/2022 18:45:38  M    update_job_usage: CPU usage: 1.829 secs
11/04/2022 18:45:38  M    update_job_usage: Memory usage: mem=23596kb
11/04/2022 18:47:39  M    update_job_usage: CPU usage: 1.853 secs
11/04/2022 18:47:39  M    update_job_usage: Memory usage: mem=23596kb
11/04/2022 18:49:41  M    update_job_usage: CPU usage: 1.875 secs
11/04/2022 18:49:41  M    update_job_usage: Memory usage: mem=23596kb
11/04/2022 18:51:42  M    update_job_usage: CPU usage: 1.897 secs
11/04/2022 18:51:42  M    update_job_usage: Memory usage: mem=23596kb
11/04/2022 18:53:26  M    task 00000001 terminated
11/04/2022 18:53:26  M    Terminated
11/04/2022 18:53:26  M    task 00000001 cput=00:00:03
11/04/2022 18:53:26  M    kill_job
11/04/2022 18:53:26  M    nid001093 cput=00:00:02 mem=23596kb
11/04/2022 18:53:26  M    update_job_usage: CPU usage: 1.910 secs
11/04/2022 18:53:26  M    update_job_usage: Memory usage: mem=23596kb

------------------------------------------------------------------
To see full PBS log data, run: /sfs/admin/scripts/tracejob.sh 17854636.cbqs01

==================================================================
END - DEBUG INFO
==================================================================

##### Job 17854636.cbqs01 - PBS Job Script:

#PBS -N run_urma_stats
#PBS -N run_urma_stats
#PBS -j oe
#PBS -j oe
#PBS -S /bin/bash
#PBS -S /bin/bash
#PBS -q "dev"
#PBS -q "dev"
#PBS -A VERF-DEV
#PBS -A VERF-DEV
#PBS -l walltime=02:00:00
#PBS -l walltime=02:00:00
#PBS -l select=1:ncpus=1:mem=2GB
#PBS -l select=1:ncpus=1:mem=2GB
#PBS -l debug=true
#PBS -l debug=true

set -x

for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
do
   export fhr
   qsub -v cyc=$fhr /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_urma_stats.ecf
   sleep 60
done

exit

##### End of job script
------------------------------------------------------------------
