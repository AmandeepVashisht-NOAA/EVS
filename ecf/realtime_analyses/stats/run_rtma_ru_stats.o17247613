Running prologue on parent mom node: nid001111...
Job 17247613.cbqs01 nodelist: nid001111
Job 17247613.cbqs01 - Prologue complete. Execution time: 3 seconds
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=00 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_rtma_ru_stats.ecf
17247615.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=01 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_rtma_ru_stats.ecf
17247638.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=02 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_rtma_ru_stats.ecf
17247661.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=03 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_rtma_ru_stats.ecf
17247682.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=04 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_rtma_ru_stats.ecf
17247731.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=05 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_rtma_ru_stats.ecf
17247917.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=06 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_rtma_ru_stats.ecf
17247934.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=07 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_rtma_ru_stats.ecf
17247960.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=08 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_rtma_ru_stats.ecf
17248027.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=09 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_rtma_ru_stats.ecf
17248106.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=10 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_rtma_ru_stats.ecf
17248196.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=11 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_rtma_ru_stats.ecf
17248322.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=12 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_rtma_ru_stats.ecf
17248347.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=13 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_rtma_ru_stats.ecf
17248366.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=14 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_rtma_ru_stats.ecf
17248412.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=15 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_rtma_ru_stats.ecf
17248524.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=16 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_rtma_ru_stats.ecf
17248558.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=17 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_rtma_ru_stats.ecf
17248594.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=18 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_rtma_ru_stats.ecf
17248621.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=19 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_rtma_ru_stats.ecf
17248912.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=20 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_rtma_ru_stats.ecf
17248944.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=21 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_rtma_ru_stats.ecf
17248967.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=22 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_rtma_ru_stats.ecf
17248993.cbqs01
++ sleep 60
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=23 /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_rtma_ru_stats.ecf
17249049.cbqs01
++ sleep 60
++ exit
Job 17247613.cbqs01 - Epilogue complete. Execution time: 2 seconds
==================================================================
BEGIN - DEBUG INFO
==================================================================
Job 17247613.cbqs01 - Post Job Mem Usage:
nid001111: 2022-10-31.25 1 ===========================================
nid001111: 2022-10-31.25 2 #### Node Memory Usage for nid001111 ####
nid001111: 2022-10-31.25 3 ------------------
nid001111: 2022-10-31.25 4 Mem: total:527077116 used:11478840 free:508749740 shared:4827120 cache:6848536 avail:508378044
nid001111: 2022-10-31.25 5 4.0K	/dev/shm
nid001111: 2022-10-31.25 6 32M	/tmp
nid001111: 2022-10-31.25 7 ===========================================
nid001111: 2022-10-31.54 1 ===========================================
nid001111: 2022-10-31.54 2 #### Node Memory Usage for nid001111 ####
nid001111: 2022-10-31.54 3 ------------------
nid001111: 2022-10-31.54 4 Mem: total:527077116 used:11493648 free:508577292 shared:4831812 cache:7006176 avail:508282224
nid001111: 2022-10-31.54 5 4.0K	/dev/shm
nid001111: 2022-10-31.54 6 32M	/tmp
nid001111: 2022-10-31.54 7 ===========================================

------------------------------------------------------------------
Job 17247613.cbqs01 - /var/log/messages for job duration:
nid001111: 2022-10-31A--:--:--.------+--:-- nid001111 #### nid001111 - Job 17247613.cbqs01 Runtime Data from /var/log/messages
nid001111: 2022-10-31T15:41:24.028589+00:00 nid001111 prologue: MARK: Job 17247613.cbqs01 Start
nid001111: 2022-10-31T15:41:24.032776+00:00 nid001111 prologue: Job 17247613.cbqs01 nodelist: nid001111
nid001111: 2022-10-31T15:41:24.033864+00:00 nid001111 prologue: Job 17247613.cbqs01 - Checking existing ASLR settings...
nid001111: 2022-10-31T15:41:24.039584+00:00 nid001111 prologue: Job 17247613.cbqs01 - Checking palsd open file count...
nid001111: 2022-10-31T15:41:24.154154+00:00 nid001111 PBS_CMD: root : /opt/pbs/bin/qstat -Bf
nid001111: 2022-10-31T15:41:25.212525+00:00 nid001111 prologue: Job 17247613.cbqs01 - Checking one-shot control: False
nid001111: 2022-10-31T15:41:25.213676+00:00 nid001111 prologue: Job 17247613.cbqs01 - Recording pre-job HSN counters...
nid001111: 2022-10-31T15:41:25.325468+00:00 nid001111 prologue: Job 17247613.cbqs01 - Recording pre-job memory usage...
nid001111: 2022-10-31T15:41:25.407258+00:00 nid001111 prologue: Job 17247613.cbqs01 - Killing any stray user processes...
nid001111: 2022-10-31T15:41:25.481281+00:00 nid001111 prologue: Job 17247613.cbqs01 - Enabling turboboost...
nid001111: 2022-10-31T15:41:25.484639+00:00 nid001111 prologue: Job 17247613.cbqs01 - Verifying post-boot workarounds...
nid001111: 2022-10-31T15:41:25.788823+00:00 nid001111 prologue: Job 17247613.cbqs01 - Warchk Complete
nid001111: 2022-10-31T15:41:25.789965+00:00 nid001111 prologue: Job 17247613.cbqs01 - Recording initial NFS client statistics...
nid001111: 2022-10-31T15:41:25.797723+00:00 nid001111 prologue: Job 17247613.cbqs01 - Prologue complete. Execution time: 3 seconds
nid001111: 2022-10-31T15:41:47.520782+00:00 nid001111 systemd[1]: session-348426.scope: Succeeded.
nid001111: 2022-10-31T15:41:55.515912+00:00 nid001111 systemd[1]: session-348427.scope: Succeeded.
nid001111: 2022-10-31T15:42:21.470424+00:00 nid001111 systemd[1]: session-348428.scope: Succeeded.
nid001111: 2022-10-31T15:42:29.871653+00:00 nid001111 systemd[1]: session-348429.scope: Succeeded.
nid001111: 2022-10-31T15:43:01.529085+00:00 nid001111 systemd[1]: session-348430.scope: Succeeded.
nid001111: 2022-10-31T15:43:09.901242+00:00 nid001111 systemd[1]: session-348431.scope: Succeeded.
nid001111: 2022-10-31T15:43:41.514376+00:00 nid001111 systemd[1]: session-348432.scope: Succeeded.
nid001111: 2022-10-31T15:43:49.887108+00:00 nid001111 systemd[1]: session-348433.scope: Succeeded.
nid001111: 2022-10-31T15:44:21.438903+00:00 nid001111 systemd[1]: session-348434.scope: Succeeded.
nid001111: 2022-10-31T15:44:29.785497+00:00 nid001111 systemd[1]: session-348435.scope: Succeeded.
nid001111: 2022-10-31T15:44:55.373965+00:00 nid001111 systemd[1]: session-348436.scope: Succeeded.
nid001111: 2022-10-31T15:44:55.747586+00:00 nid001111 systemd[1]: session-348437.scope: Succeeded.
nid001111: 2022-10-31T15:44:55.748026+00:00 nid001111 systemd[1]: session-348438.scope: Succeeded.
nid001111: 2022-10-31T15:45:01.448206+00:00 nid001111 systemd[1]: session-348440.scope: Succeeded.
nid001111: 2022-10-31T15:45:09.851988+00:00 nid001111 systemd[1]: session-348441.scope: Succeeded.
nid001111: 2022-10-31T15:45:41.370143+00:00 nid001111 systemd[1]: session-348442.scope: Succeeded.
nid001111: 2022-10-31T15:45:49.738306+00:00 nid001111 systemd[1]: session-348443.scope: Succeeded.
nid001111: 2022-10-31T15:46:21.468749+00:00 nid001111 systemd[1]: session-348444.scope: Succeeded.
nid001111: 2022-10-31T15:46:29.864021+00:00 nid001111 systemd[1]: session-348445.scope: Succeeded.
nid001111: 2022-10-31T15:47:02.786441+00:00 nid001111 systemd[1]: session-348446.scope: Succeeded.
nid001111: 2022-10-31T15:47:11.959581+00:00 nid001111 systemd[1]: session-348447.scope: Succeeded.
nid001111: 2022-10-31T15:47:36.420011+00:00 nid001111 systemd[1]: session-348448.scope: Succeeded.
nid001111: 2022-10-31T15:47:44.800591+00:00 nid001111 systemd[1]: session-348449.scope: Succeeded.
nid001111: 2022-10-31T15:47:50.894513+00:00 nid001111 systemd[1]: session-348439.scope: Succeeded.
nid001111: 2022-10-31T15:48:16.886465+00:00 nid001111 systemd[1]: session-348450.scope: Succeeded.
nid001111: 2022-10-31T15:48:25.379710+00:00 nid001111 systemd[1]: session-348451.scope: Succeeded.
nid001111: 2022-10-31T15:48:51.436876+00:00 nid001111 systemd[1]: session-348452.scope: Succeeded.
nid001111: 2022-10-31T15:48:59.835969+00:00 nid001111 systemd[1]: session-348453.scope: Succeeded.
nid001111: 2022-10-31T15:49:31.379553+00:00 nid001111 systemd[1]: session-348454.scope: Succeeded.
nid001111: 2022-10-31T15:49:39.729376+00:00 nid001111 systemd[1]: session-348455.scope: Succeeded.
nid001111: 2022-10-31T15:50:04.522600+00:00 nid001111 systemd[1]: session-348197.scope: Succeeded.
nid001111: 2022-10-31T15:50:14.498511+00:00 nid001111 systemd[1]: session-348456.scope: Succeeded.
nid001111: 2022-10-31T15:50:22.721456+00:00 nid001111 systemd[1]: session-348457.scope: Succeeded.
nid001111: 2022-10-31T15:50:34.986571+00:00 nid001111 systemd[1]: etc_update.service: Succeeded.
nid001111: 2022-10-31T15:50:56.391470+00:00 nid001111 systemd[1]: session-348459.scope: Succeeded.
nid001111: 2022-10-31T15:51:04.768274+00:00 nid001111 systemd[1]: session-348460.scope: Succeeded.
nid001111: 2022-10-31T15:51:36.446543+00:00 nid001111 systemd[1]: session-348461.scope: Succeeded.
nid001111: 2022-10-31T15:51:44.815147+00:00 nid001111 systemd[1]: session-348462.scope: Succeeded.
nid001111: 2022-10-31T15:52:16.880536+00:00 nid001111 systemd[1]: session-348463.scope: Succeeded.
nid001111: 2022-10-31T15:52:25.238239+00:00 nid001111 systemd[1]: session-348464.scope: Succeeded.
nid001111: 2022-10-31T15:52:56.455098+00:00 nid001111 systemd[1]: session-348465.scope: Succeeded.
nid001111: 2022-10-31T15:53:04.854728+00:00 nid001111 systemd[1]: session-348466.scope: Succeeded.
nid001111: 2022-10-31T15:53:36.411443+00:00 nid001111 systemd[1]: session-348467.scope: Succeeded.
nid001111: 2022-10-31T15:53:44.795196+00:00 nid001111 systemd[1]: session-348468.scope: Succeeded.
nid001111: 2022-10-31T15:54:16.723759+00:00 nid001111 systemd[1]: session-348469.scope: Succeeded.
nid001111: 2022-10-31T15:54:25.077601+00:00 nid001111 systemd[1]: session-348470.scope: Succeeded.
nid001111: 2022-10-31T15:54:55.943944+00:00 nid001111 systemd[1]: session-348471.scope: Succeeded.
nid001111: 2022-10-31T15:55:04.286695+00:00 nid001111 systemd[1]: session-348472.scope: Succeeded.
nid001111: 2022-10-31T15:55:36.709691+00:00 nid001111 systemd[1]: session-348473.scope: Succeeded.
nid001111: 2022-10-31T15:55:44.963009+00:00 nid001111 systemd[1]: session-348474.scope: Succeeded.
nid001111: 2022-10-31T15:56:16.688002+00:00 nid001111 systemd[1]: session-348475.scope: Succeeded.
nid001111: 2022-10-31T15:56:24.938541+00:00 nid001111 systemd[1]: session-348476.scope: Succeeded.
nid001111: 2022-10-31T15:56:56.390060+00:00 nid001111 systemd[1]: session-348477.scope: Succeeded.
nid001111: 2022-10-31T15:57:04.753317+00:00 nid001111 systemd[1]: session-348478.scope: Succeeded.
nid001111: 2022-10-31T15:57:36.977977+00:00 nid001111 systemd[1]: session-348479.scope: Succeeded.
nid001111: 2022-10-31T15:57:45.609210+00:00 nid001111 systemd[1]: session-348480.scope: Succeeded.
nid001111: 2022-10-31T15:58:11.376650+00:00 nid001111 systemd[1]: session-348481.scope: Succeeded.
nid001111: 2022-10-31T15:58:19.733941+00:00 nid001111 systemd[1]: session-348482.scope: Succeeded.
nid001111: 2022-10-31T15:58:51.442678+00:00 nid001111 systemd[1]: session-348483.scope: Succeeded.
nid001111: 2022-10-31T15:58:59.854039+00:00 nid001111 systemd[1]: session-348484.scope: Succeeded.
nid001111: 2022-10-31T15:59:31.424401+00:00 nid001111 systemd[1]: session-348485.scope: Succeeded.
nid001111: 2022-10-31T15:59:39.818960+00:00 nid001111 systemd[1]: session-348486.scope: Succeeded.
nid001111: 2022-10-31T16:00:14.659517+00:00 nid001111 systemd[1]: Started Timeline of Snapper Snapshots.
nid001111: 2022-10-31T16:00:14.991007+00:00 nid001111 systemd[1]: session-348487.scope: Succeeded.
nid001111: 2022-10-31T16:00:15.142314+00:00 nid001111 dbus-daemon[5556]: [system] Activating via systemd: service name='org.opensuse.Snapper' unit='snapperd.service' requested by ':1.702128' (uid=0 pid=16622 comm="/usr/lib/snapper/systemd-helper --timeline ")
nid001111: 2022-10-31T16:00:15.145721+00:00 nid001111 systemd[1]: Starting DBus interface for snapper...
nid001111: 2022-10-31T16:00:15.170175+00:00 nid001111 dbus-daemon[5556]: [system] Successfully activated service 'org.opensuse.Snapper'
nid001111: 2022-10-31T16:00:15.170954+00:00 nid001111 systemd[1]: Started DBus interface for snapper.
nid001111: 2022-10-31T16:00:15.175213+00:00 nid001111 systemd[1]: snapper-timeline.service: Succeeded.
nid001111: 2022-10-31T16:00:23.361233+00:00 nid001111 systemd[1]: session-348488.scope: Succeeded.
nid001111: 2022-10-31T16:00:51.513761+00:00 nid001111 systemd[1]: session-348489.scope: Succeeded.
nid001111: 2022-10-31T16:00:59.882631+00:00 nid001111 systemd[1]: session-348490.scope: Succeeded.
nid001111: 2022-10-31T16:01:15.237665+00:00 nid001111 systemd[1]: snapperd.service: Succeeded.
nid001111: 2022-10-31T16:01:31.427137+00:00 nid001111 systemd[1]: session-348491.scope: Succeeded.
nid001111: 2022-10-31T16:01:39.802347+00:00 nid001111 systemd[1]: session-348492.scope: Succeeded.
nid001111: 2022-10-31T16:02:11.134028+00:00 nid001111 systemd[1]: etc_update.service: Succeeded.
nid001111: 2022-10-31T16:02:11.431972+00:00 nid001111 systemd[1]: session-348493.scope: Succeeded.
nid001111: 2022-10-31T16:02:19.824719+00:00 nid001111 systemd[1]: session-348494.scope: Succeeded.
nid001111: 2022-10-31T16:02:51.363255+00:00 nid001111 systemd[1]: session-348495.scope: Succeeded.
nid001111: 2022-10-31T16:02:59.808390+00:00 nid001111 systemd[1]: session-348496.scope: Succeeded.
nid001111: 2022-10-31T16:03:31.411785+00:00 nid001111 systemd[1]: session-348497.scope: Succeeded.
nid001111: 2022-10-31T16:03:39.790141+00:00 nid001111 systemd[1]: session-348498.scope: Succeeded.
nid001111: 2022-10-31T16:04:11.453239+00:00 nid001111 systemd[1]: session-348499.scope: Succeeded.
nid001111: 2022-10-31T16:04:19.846973+00:00 nid001111 systemd[1]: session-348500.scope: Succeeded.
nid001111: 2022-10-31T16:04:51.432377+00:00 nid001111 systemd[1]: session-348501.scope: Succeeded.
nid001111: 2022-10-31T16:04:59.828054+00:00 nid001111 systemd[1]: session-348502.scope: Succeeded.
nid001111: 2022-10-31T16:05:31.633927+00:00 nid001111 systemd[1]: session-348503.scope: Succeeded.
nid001111: 2022-10-31T16:05:39.984646+00:00 nid001111 systemd[1]: session-348504.scope: Succeeded.
nid001111: 2022-10-31T16:05:54.764591+00:00 nid001111 epilogue: Job 17247613.cbqs01 complete, running post-job actions.
nid001111: 2022-10-31T16:05:54.782685+00:00 nid001111 epilogue: Job 17247613.cbqs01 - Recording post-job HSN counters...
nid001111: 2022-10-31T16:05:54.890002+00:00 nid001111 epilogue: Job 17247613.cbqs01 - Recording post-job memory usage...
nid001111: 2022-10-31T16:05:54.909587+00:00 nid001111 epilogue: Job 17247613.cbqs01 - Recording job NFS statistics to /tmp/nfsstats.17247613.cbqs01
nid001111: 2022-10-31T16:05:55.406832+00:00 nid001111 epilogue: Job 17247613.cbqs01 - Clearing /tmp...
nid001111: 2022-10-31T16:05:55.433894+00:00 nid001111 epilogue: Job 17247613.cbqs01 - Clearing shared memory...
nid001111: 2022-10-31T16:05:55.447718+00:00 nid001111 epilogue: Job 17247613.cbqs01 - Clearing memory cache...
nid001111: 2022-10-31T16:05:55.911293+00:00 nid001111 kernel: [7614227.416419] drop_caches (18710): drop_caches: 3
nid001111: 2022-10-31T16:05:56.082739+00:00 nid001111 epilogue: Job 17247613.cbqs01 - Releasing Lustre Locks...
nid001111: 2022-10-31T16:05:56.103088+00:00 nid001111 epilogue: MARK: Job 17247613.cbqs01 Complete.

------------------------------------------------------------------
Job 17247613.cbqs01 - dmesg output for job duration:
nid001111: 2022-10-31A--:--:--.------+--:-- nid001111 #### nid001111 - Job 17247613.cbqs01 Runtime Data from dmesg
nid001111: [Mon Oct 31 15:38:31 2022] MARK: Job 17247613.cbqs01 Start
nid001111: [Mon Oct 31 16:03:03 2022] MARK: Job 17247613.cbqs01 Complete.
nid001111: [Mon Oct 31 16:03:03 2022] drop_caches (18710): drop_caches: 3

------------------------------------------------------------------
Job 17247613.cbqs01 - Pre/Post job diff on HSN (MLX) Counters:
nid001111: 2022-10-31A--:--:--.------+--:-- nid001111 #### nid001111 - Job 17247613.cbqs01 HSN0 MLX Counter Post-Job Difference
nid001111: multicast: 300327066					      |	multicast: 300327129
nid001111: port_rcv_data: 468117232991159				      |	port_rcv_data: 468117233312219
nid001111: port_rcv_packets: 841617728202				      |	port_rcv_packets: 841617734675
nid001111: port_xmit_data: 475344967030809				      |	port_xmit_data: 475344967369717
nid001111: port_xmit_packets: 857270256938				      |	port_xmit_packets: 857270263418
nid001111: rx_bytes: 1272275993171					      |	rx_bytes: 1272284389273
nid001111: rx_packets: 1414526273					      |	rx_packets: 1414540218
nid001111: tx_bytes: 683361619825					      |	tx_bytes: 683364347778
nid001111: tx_packets: 733126010					      |	tx_packets: 733142166
nid001111: unicast_rcv_packets: 841617728202			      |	unicast_rcv_packets: 841617734675
nid001111: unicast_xmit_packets: 857270256938			      |	unicast_xmit_packets: 857270263418

------------------------------------------------------------------
### Job 17247613.cbqs01 - NFS Statistics for job duration:
nid001111: #### 2022-10-31.00 #### nid001111 - Job 17247613.cbqs01 NFS Statistics for job duration (nfsstat)
nid001111: ## /usr/sbin/nfsstat -v -S /tmp/nfsstats.begin.17247613.cbqs01 :
nid001111: Client packet stats:
nid001111: packets    udp        tcp        tcpconn
nid001111: 0          0          0          0       
nid001111: 
nid001111: Client rpc stats:
nid001111: calls      retrans    authrefrsh
nid001111: 10039      0          10039   
nid001111: 
nid001111: Client nfs v3:
nid001111: null             getattr          setattr          lookup           access           
nid001111: 0         0%     8473     84%     2         0%     351       3%     393       3%     
nid001111: readlink         read             write            create           mkdir            
nid001111: 48        0%     487       4%     70        0%     0         0%     0         0%     
nid001111: symlink          mknod            remove           rmdir            rename           
nid001111: 0         0%     0         0%     0         0%     0         0%     0         0%     
nid001111: link             readdir          readdirplus      fsstat           fsinfo           
nid001111: 0         0%     0         0%     215       2%     0         0%     0         0%     
nid001111: pathconf         commit           
nid001111: 0         0%     0         0%     
nid001111: 
nid001111: 
nid001111: -----------------------------------------------------------------------------------
nid001111: 
nid001111: #### 2022-10-31.00 #### nid001111 - Job 17247613.cbqs01 NFS Mount Statistics for job duration (mountstats)
nid001111: ## /usr/sbin/mountstats iostat -S /tmp/mntstats.begin.17247613.cbqs01 /apps :
nid001111: 
nid001111: 
nid001111: 172.20.250.16:/AZ-HFS-Cactus-apps mounted on /apps:
nid001111: 
nid001111:            ops/s       rpc bklog
nid001111:            5.793           0.000
nid001111: 
nid001111: read:              ops/s            kB/s           kB/op         retrans    avg RTT (ms)    avg exe (ms)
nid001111:                    0.055           0.118           2.145        0 (0.0%)           0.235           0.272
nid001111: write:             ops/s            kB/s           kB/op         retrans    avg RTT (ms)    avg exe (ms)
nid001111:                    0.000           0.000           0.000        0 (0.0%)           0.000           0.000
nid001111: ## /usr/sbin/mountstats iostat -S /tmp/mntstats.begin.17247613.cbqs01 /sfs :
nid001111: 
nid001111: 
nid001111: 172.20.250.16:/AZ-HFS-Cactus-sfs mounted on /sfs:
nid001111: 
nid001111:            ops/s       rpc bklog
nid001111:            5.789           0.000
nid001111: 
nid001111: read:              ops/s            kB/s           kB/op         retrans    avg RTT (ms)    avg exe (ms)
nid001111:                    0.002           0.003           1.616        0 (0.0%)           0.333           0.667
nid001111: write:             ops/s            kB/s           kB/op         retrans    avg RTT (ms)    avg exe (ms)
nid001111:                    0.048           0.246           5.157        0 (0.0%)           0.643           0.757
nid001111: ## /usr/sbin/mountstats iostat -S /tmp/mntstats.begin.17247613.cbqs01 /u :
nid001111: 
nid001111: 
nid001111: 172.20.250.17:/AZ-HFS-Cactus-u mounted on /u:
nid001111: 
nid001111:            ops/s       rpc bklog
nid001111:            0.067           0.000
nid001111: 
nid001111: read:              ops/s            kB/s           kB/op         retrans    avg RTT (ms)    avg exe (ms)
nid001111:                    0.001           0.001           0.969        0 (0.0%)           1.000           0.000
nid001111: write:             ops/s            kB/s           kB/op         retrans    avg RTT (ms)    avg exe (ms)
nid001111:                    0.000           0.000           0.000        0 (0.0%)           0.000           0.000
nid001111: ## /usr/sbin/mountstats iostat -S /tmp/mntstats.begin.17247613.cbqs01 /pe :
nid001111: 
nid001111: 
nid001111: 10.31.62.243:/cm_shared/image/images_rw_nfs/pe mounted on /pe:
nid001111: 
nid001111:            ops/s       rpc bklog
nid001111:            1.056           0.000
nid001111: 
nid001111: read:              ops/s            kB/s           kB/op         retrans    avg RTT (ms)    avg exe (ms)
nid001111:                    0.027           4.130         151.780        0 (0.0%)           2.525           2.575
nid001111: write:             ops/s            kB/s           kB/op         retrans    avg RTT (ms)    avg exe (ms)
nid001111:                    0.000           0.000           0.000        0 (0.0%)           0.000           0.000
nid001111: ----------------
nid001111: ## /usr/sbin/mountstats mountstats -S /tmp/mntstats.begin.17247613.cbqs01 /apps :
nid001111: Stats for 172.20.250.16:/AZ-HFS-Cactus-apps mounted on /apps:
nid001111:   NFS mount options: ro,vers=3,rsize=65536,wsize=65536,namlen=255,acregmin=3,acregmax=60,acdirmin=30,acdirmax=60,hard,proto=tcp,timeo=600,retrans=2,sec=sys,mountaddr=172.20.250.16,mountvers=3,mountport=4048,mountproto=udp,local_lock=none
nid001111:   NFS server capabilities: caps=0x3fc7,wtmult=4096,dtsize=8192,bsize=0,namlen=255
nid001111:   NFS security flavor: 1  pseudoflavor: 0
nid001111: 
nid001111: NFS byte counts:
nid001111:   applications read 6227196 bytes via read(2)
nid001111:   applications wrote 0 bytes via write(2)
nid001111:   applications read 0 bytes via O_DIRECT read(2)
nid001111:   applications wrote 0 bytes via O_DIRECT write(2)
nid001111:   client read 154112 bytes via NFS READ
nid001111:   client wrote 0 bytes via NFS WRITE
nid001111: 
nid001111: RPC statistics:
nid001111:   8510 RPC requests sent, 8510 RPC replies received (0 XIDs not found)
nid001111:   average backlog queue length: 0
nid001111: 
nid001111: GETATTR:
nid001111: 	7514 ops (88%) 
nid001111: 	avg bytes sent per op: avg bytes received per op: 112
nid001111: 	backlog wait: 0.002129 	RTT: 0.227043 	total execute time: 0.237956 (milliseconds)
nid001111: ACCESS:
nid001111: 	315 ops (3%) 
nid001111: 	avg bytes sent per op: avg bytes received per op: 120
nid001111: 	backlog wait: 0.003175 	RTT: 0.282540 	total execute time: 0.292063 (milliseconds)
nid001111: READDIRPLUS:
nid001111: 	215 ops (2%) 
nid001111: 	avg bytes sent per op: avg bytes received per op: 942
nid001111: 	backlog wait: 0.000000 	RTT: 0.148837 	total execute time: 0.153488 (milliseconds)
nid001111: LOOKUP:
nid001111: 	173 ops (2%) 
nid001111: 	avg bytes sent per op: avg bytes received per op: 164
nid001111: 	backlog wait: 0.000000 	RTT: 0.109827 	total execute time: 0.121387 (milliseconds)
nid001111: READ:
nid001111: 	81 ops (0%) 
nid001111: 	avg bytes sent per op: avg bytes received per op: 2032
nid001111: 	backlog wait: 0.024691 	RTT: 0.234568 	total execute time: 0.271605 (milliseconds)
nid001111: READLINK:
nid001111: 	46 ops (0%) 
nid001111: 	avg bytes sent per op: avg bytes received per op: 135
nid001111: 	backlog wait: 0.000000 	RTT: 0.086957 	total execute time: 0.108696 (milliseconds)
nid001111: 
nid001111: ## /usr/sbin/mountstats mountstats -S /tmp/mntstats.begin.17247613.cbqs01 /sfs :
nid001111: 
nid001111: Stats for 172.20.250.16:/AZ-HFS-Cactus-sfs mounted on /sfs:
nid001111:   NFS mount options: rw,vers=3,rsize=65536,wsize=65536,namlen=255,acregmin=3,acregmax=60,acdirmin=30,acdirmax=60,hard,proto=tcp,timeo=600,retrans=2,sec=sys,mountaddr=172.20.250.16,mountvers=3,mountport=4048,mountproto=udp,local_lock=none
nid001111:   NFS server capabilities: caps=0x3fc7,wtmult=4096,dtsize=8192,bsize=0,namlen=255
nid001111:   NFS security flavor: 1  pseudoflavor: 0
nid001111: 
nid001111: NFS byte counts:
nid001111:   applications read 13847 bytes via read(2)
nid001111:   applications wrote 220929 bytes via write(2)
nid001111:   applications read 0 bytes via O_DIRECT read(2)
nid001111:   applications wrote 0 bytes via O_DIRECT write(2)
nid001111:   client read 4186 bytes via NFS READ
nid001111:   client wrote 348588 bytes via NFS WRITE
nid001111: 
nid001111: RPC statistics:
nid001111:   8510 RPC requests sent, 8510 RPC replies received (0 XIDs not found)
nid001111:   average backlog queue length: 0
nid001111: 
nid001111: GETATTR:
nid001111: 	79 ops (0%) 
nid001111: 	avg bytes sent per op: avg bytes received per op: 112
nid001111: 	backlog wait: 0.000000 	RTT: 0.164557 	total execute time: 0.215190 (milliseconds)
nid001111: WRITE:
nid001111: 	70 ops (0%) 
nid001111: 	avg bytes sent per op: avg bytes received per op: 160
nid001111: 	backlog wait: 0.042857 	RTT: 0.642857 	total execute time: 0.757143 (milliseconds)
nid001111: ACCESS:
nid001111: 	7 ops (0%) 
nid001111: 	avg bytes sent per op: avg bytes received per op: 120
nid001111: 	backlog wait: 0.000000 	RTT: 0.285714 	total execute time: 0.142857 (milliseconds)
nid001111: LOOKUP:
nid001111: 	5 ops (0%) 
nid001111: 	avg bytes sent per op: avg bytes received per op: 240
nid001111: 	backlog wait: 0.000000 	RTT: 0.000000 	total execute time: 0.200000 (milliseconds)
nid001111: READ:
nid001111: 	3 ops (0%) 
nid001111: 	avg bytes sent per op: avg bytes received per op: 1525
nid001111: 	backlog wait: 0.333333 	RTT: 0.333333 	total execute time: 0.666667 (milliseconds)
nid001111: SETATTR:
nid001111: 	2 ops (0%) 
nid001111: 	avg bytes sent per op: avg bytes received per op: 144
nid001111: 	backlog wait: 0.000000 	RTT: 0.000000 	total execute time: 0.500000 (milliseconds)
nid001111: 
nid001111: ## /usr/sbin/mountstats mountstats -S /tmp/mntstats.begin.17247613.cbqs01 /u :
nid001111: 
nid001111: Stats for 172.20.250.17:/AZ-HFS-Cactus-u mounted on /u:
nid001111:   NFS mount options: rw,vers=3,rsize=65536,wsize=65536,namlen=255,acregmin=3,acregmax=60,acdirmin=30,acdirmax=60,hard,proto=tcp,timeo=600,retrans=2,sec=sys,mountaddr=172.20.250.17,mountvers=3,mountport=4048,mountproto=udp,local_lock=none
nid001111:   NFS server capabilities: caps=0x3fc7,wtmult=4096,dtsize=8192,bsize=0,namlen=255
nid001111:   NFS security flavor: 1  pseudoflavor: 0
nid001111: 
nid001111: NFS byte counts:
nid001111:   applications read 701 bytes via read(2)
nid001111:   applications wrote 0 bytes via write(2)
nid001111:   applications read 0 bytes via O_DIRECT read(2)
nid001111:   applications wrote 0 bytes via O_DIRECT write(2)
nid001111:   client read 701 bytes via NFS READ
nid001111:   client wrote 0 bytes via NFS WRITE
nid001111: 
nid001111: RPC statistics:
nid001111:   99 RPC requests sent, 99 RPC replies received (0 XIDs not found)
nid001111:   average backlog queue length: 0
nid001111: 
nid001111: GETATTR:
nid001111: 	47 ops (47%) 
nid001111: 	avg bytes sent per op: avg bytes received per op: 112
nid001111: 	backlog wait: 0.000000 	RTT: 0.234043 	total execute time: 0.255319 (milliseconds)
nid001111: ACCESS:
nid001111: 	37 ops (37%) 
nid001111: 	avg bytes sent per op: avg bytes received per op: 120
nid001111: 	backlog wait: 0.000000 	RTT: 0.135135 	total execute time: 0.162162 (milliseconds)
nid001111: LOOKUP:
nid001111: 	14 ops (14%) 
nid001111: 	avg bytes sent per op: avg bytes received per op: 142
nid001111: 	backlog wait: 0.000000 	RTT: 0.142857 	total execute time: 0.214286 (milliseconds)
nid001111: READ:
nid001111: 	1 ops (1%) 
nid001111: 	avg bytes sent per op: avg bytes received per op: 832
nid001111: 	backlog wait: 0.000000 	RTT: 1.000000 	total execute time: 0.000000 (milliseconds)
nid001111: 
nid001111: ## /usr/sbin/mountstats mountstats -S /tmp/mntstats.begin.17247613.cbqs01 /pe :
nid001111: 
nid001111: Stats for 10.31.62.243:/cm_shared/image/images_rw_nfs/pe mounted on /pe:
nid001111:   NFS mount options: ro,vers=3,rsize=1048576,wsize=1048576,namlen=255,acregmin=3,acregmax=60,acdirmin=30,acdirmax=60,hard,nolock,proto=tcp,timeo=600,retrans=2,sec=sys,mountaddr=10.31.62.243,mountvers=3,mountport=38465,mountproto=tcp,local_lock=all
nid001111:   NFS server capabilities: caps=0x3fcf,wtmult=4096,dtsize=32768,bsize=0,namlen=255
nid001111:   NFS security flavor: 1  pseudoflavor: 0
nid001111: 
nid001111: NFS byte counts:
nid001111:   applications read 1253376 bytes via read(2)
nid001111:   applications wrote 0 bytes via write(2)
nid001111:   applications read 0 bytes via O_DIRECT read(2)
nid001111:   applications wrote 0 bytes via O_DIRECT write(2)
nid001111:   client read 6209536 bytes via NFS READ
nid001111:   client wrote 0 bytes via NFS WRITE
nid001111: 
nid001111: RPC statistics:
nid001111:   1553 RPC requests sent, 1554 RPC replies received (0 XIDs not found)
nid001111:   average backlog queue length: 0
nid001111: 
nid001111: GETATTR:
nid001111: 	833 ops (53%) 
nid001111: 	avg bytes sent per op: avg bytes received per op: 112
nid001111: 	backlog wait: 0.001200 	RTT: 0.344538 	total execute time: 0.356543 (milliseconds)
nid001111: LOOKUP:
nid001111: 	159 ops (10%) 
nid001111: 	avg bytes sent per op: avg bytes received per op: 82
nid001111: 	backlog wait: 0.006289 	RTT: 0.540881 	total execute time: 0.547170 (milliseconds)
nid001111: READ:
nid001111: 	40 ops (2%) 
nid001111: 	avg bytes sent per op: avg bytes received per op: 155282
nid001111: 	backlog wait: 0.025000 	RTT: 2.525000 	total execute time: 2.575000 (milliseconds)
nid001111: ACCESS:
nid001111: 	34 ops (2%) 
nid001111: 	avg bytes sent per op: avg bytes received per op: 36
nid001111: 	backlog wait: 0.000000 	RTT: 0.323529 	total execute time: 0.323529 (milliseconds)
nid001111: READLINK:
nid001111: 	2 ops (0%) 
nid001111: 	avg bytes sent per op: avg bytes received per op: 136
nid001111: 	backlog wait: 0.000000 	RTT: 0.000000 	total execute time: 0.000000 (milliseconds)
nid001111: 
nid001111: 

------------------------------------------------------------------
### Job 17247613.cbqs01 - Exit status is 0

------------------------------------------------------------------
Job 17247613.cbqs01 - Job summary:
Job Id: 17247613.cbqs01
    Job_Name = run_rtma_ru_stats
    Job_Owner = perry.shafran@clogin02.cactus.wcoss2.ncep.noaa.gov
    resources_used.cpupercent = 1
    resources_used.cput = 00:00:02
    resources_used.mem = 25480kb
    resources_used.ncpus = 1
    resources_used.vmem = 45872kb
    resources_used.walltime = 00:24:14
    job_state = R
    queue = dev
    server = cbqs01
    Account_Name = VERF-DEV
    Checkpoint = u
    ctime = Mon Oct 31 15:41:21 2022
    Error_Path = clogin02.cactus.wcoss2.ncep.noaa.gov:/lfs/h2/emc/vpppg/save/pe
	rry.shafran/EVS/ecf/realtime_analyses/stats/run_rtma_ru_stats.e17247613
	
    exec_host = nid001111/0
    exec_vnode = (nid001111:ncpus=1:mem=2097152kb)
    Hold_Types = n
    Join_Path = oe
    Keep_Files = oed
    Mail_Points = a
    mtime = Mon Oct 31 16:05:43 2022
    Output_Path = clogin02.cactus.wcoss2.ncep.noaa.gov:/lfs/h2/emc/vpppg/save/p
	erry.shafran/EVS/ecf/realtime_analyses/stats/run_rtma_ru_stats.o1724761
	3
    Priority = 0
    qtime = Mon Oct 31 15:41:21 2022
    Rerunable = False
    Resource_List.alvl = 2
    Resource_List.aslr = True
    Resource_List.debug = True
    Resource_List.dfs = False
    Resource_List.hyper = False
    Resource_List.mem = 2gb
    Resource_List.ncpus = 1
    Resource_List.nodect = 1
    Resource_List.one-shot = False
    Resource_List.place = shared
    Resource_List.select = 1:ncpus=1:mem=2GB
    Resource_List.thp = True
    Resource_List.turbo = True
    Resource_List.walltime = 02:00:00
    schedselect = 1:ncpus=1:mem=2GB:prepost=False
    stime = Mon Oct 31 15:41:22 2022
    session_id = 7408
    Shell_Path_List = /bin/bash
    jobdir = /u/perry.shafran
    substate = 42
    Variable_List = PBS_O_HOME=/u/perry.shafran,PBS_O_LANG=en_US.UTF-8,
	PBS_O_LOGNAME=perry.shafran,
	PBS_O_PATH=/apps/ops/prod/nco/core/prod_util.v2.0.14/ush:/apps/prod/hp
	c-stack/intel-19.1.3.304/netcdf/4.7.4/bin:/apps/prod/hpc-stack/intel-19
	.1.3.304/hdf5/1.10.6/bin:/apps/spack/python/3.8.6/intel/19.1.3.304/pjn2
	nzkjvqgmjw4hmyz43v5x4jbxjzpk/bin:/apps/ops/para/libs/intel/19.1.3.304/m
	etplus/4.1.1/ush:/apps/ops/para/libs/intel/19.1.3.304/met/10.1.1/bin:/a
	pps/ops/para/libs/intel/19.1.3.304/gsl/2.6/bin:/pe/intel/compilers_and_
	libraries_2020.4.304/linux/bin/intel64:/pe/intel/compilers_and_librarie
	s_2020.4.304/linux/bin:/pe/intel/compilers_and_libraries_2020.4.304/lin
	ux/mpi/intel64/bin:/pe/intel/debugger_2020/gdb/intel64/bin:/opt/cray/li
	bfabric/1.11.0.0./bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt
	/sgi/bin:/usr/local/bin:/usr/bin:/bin:/usr/lib/mit/bin:/usr/lib/mit/sbi
	n:/opt/pbs/bin:/sbin:.:/u/perry.shafran/bin:/usr/sbin:/apps/prod/python
	-modules/3.8.6/intel/19.1.3.304/bin:/apps/prod/python-modules/3.8.6/int
	el/19.1.3.304/lib/python3.8/site-packages/bin,
	PBS_O_MAIL=/var/spool/mail/perry.shafran,PBS_O_SHELL=/bin/bash,
	PBS_O_WORKDIR=/lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_an
	alyses/stats,PBS_O_SYSTEM=Linux,PBS_O_QUEUE=dev,
	PBS_O_HOST=clogin02.cactus.wcoss2.ncep.noaa.gov
    euser = perry.shafran
    egroup = emc
    hashname = 17247613.cbqs01
    queue_rank = 1667230881497
    queue_type = E
    comment = Job run at Mon Oct 31 at 15:41 on (nid001111:ncpus=1:mem=2097152k
	b)
    etime = Mon Oct 31 15:41:21 2022
    umask = 22
    run_count = 6
    eligible_time = 00:00:00
    accrue_type = 3
    Submit_arguments = run_rtma_ru_stats.sh
    project = VERF-DEV
    run_version = 1
    Submit_Host = clogin02.cactus.wcoss2.ncep.noaa.gov


------------------------------------------------------------------
Job 17247613.cbqs01 - PBS tracejob output (for parent mom node only):

Job: 17247613.cbqs01

10/31/2022 15:41:22  M    update_job_usage: CPU usage: 0.000 secs
10/31/2022 15:41:22  M    update_job_usage: cpupercent initialized to zero
10/31/2022 15:41:22  M    update_job_usage: Memory usage: mem=0b
10/31/2022 15:41:22  M    no active tasks
10/31/2022 15:41:26  M    Started, pid = 7408
10/31/2022 15:43:20  M    update_job_usage: CPU usage: 1.730 secs
10/31/2022 15:43:20  M    update_job_usage: 17247613.cbqs01 measured interval cpupercent 1 increased job cpupercent to 1
10/31/2022 15:43:20  M    update_job_usage: Memory usage: mem=25480kb
10/31/2022 15:45:25  M    update_job_usage: CPU usage: 1.754 secs
10/31/2022 15:45:25  M    update_job_usage: Memory usage: mem=25480kb
10/31/2022 15:47:29  M    update_job_usage: CPU usage: 1.780 secs
10/31/2022 15:47:29  M    update_job_usage: Memory usage: mem=25480kb
10/31/2022 15:49:33  M    update_job_usage: CPU usage: 1.804 secs
10/31/2022 15:49:33  M    update_job_usage: Memory usage: mem=25480kb
10/31/2022 15:51:37  M    update_job_usage: CPU usage: 1.826 secs
10/31/2022 15:51:37  M    update_job_usage: Memory usage: mem=25480kb
10/31/2022 15:53:41  M    update_job_usage: CPU usage: 1.851 secs
10/31/2022 15:53:41  M    update_job_usage: Memory usage: mem=25480kb
10/31/2022 15:55:45  M    update_job_usage: CPU usage: 1.887 secs
10/31/2022 15:55:45  M    update_job_usage: Memory usage: mem=25480kb
10/31/2022 15:57:49  M    update_job_usage: CPU usage: 1.903 secs
10/31/2022 15:57:49  M    update_job_usage: Memory usage: mem=25480kb
10/31/2022 15:59:53  M    update_job_usage: CPU usage: 1.939 secs
10/31/2022 15:59:53  M    update_job_usage: Memory usage: mem=25480kb
10/31/2022 16:01:57  M    update_job_usage: CPU usage: 1.964 secs
10/31/2022 16:01:57  M    update_job_usage: Memory usage: mem=25480kb
10/31/2022 16:04:01  M    update_job_usage: CPU usage: 1.987 secs
10/31/2022 16:04:01  M    update_job_usage: Memory usage: mem=25480kb
10/31/2022 16:05:54  M    task 00000001 terminated
10/31/2022 16:05:54  M    Terminated
10/31/2022 16:05:54  M    task 00000001 cput=00:00:03
10/31/2022 16:05:54  M    kill_job
10/31/2022 16:05:54  M    nid001111 cput=00:00:02 mem=25480kb
10/31/2022 16:05:54  M    update_job_usage: CPU usage: 2.002 secs
10/31/2022 16:05:54  M    update_job_usage: Memory usage: mem=25480kb

------------------------------------------------------------------
To see full PBS log data, run: /sfs/admin/scripts/tracejob.sh 17247613.cbqs01

==================================================================
END - DEBUG INFO
==================================================================

##### Job 17247613.cbqs01 - PBS Job Script:

#PBS -N run_rtma_ru_stats
#PBS -N run_rtma_ru_stats
#PBS -j oe
#PBS -j oe
#PBS -S /bin/bash
#PBS -S /bin/bash
#PBS -q "dev"
#PBS -q "dev"
#PBS -A VERF-DEV
#PBS -A VERF-DEV
#PBS -l walltime=02:00:00
#PBS -l walltime=02:00:00
#PBS -l select=1:ncpus=1:mem=2GB
#PBS -l select=1:ncpus=1:mem=2GB
#PBS -l debug=true
#PBS -l debug=true

set -x

for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
do
   export fhr
   qsub -v cyc=$fhr /lfs/h2/emc/vpppg/save/perry.shafran/EVS/ecf/realtime_analyses/stats/jevs_rtma_ru_stats.ecf
   sleep 60
done

exit

##### End of job script
------------------------------------------------------------------
