Running prologue on parent mom node: nid001703...
Job 17052798.cbqs01 nodelist: nid001703
Job 17052798.cbqs01 - Prologue complete. Execution time: 3 seconds
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=00 /lfs/h2/emc/vpppg/save/perry.shafran/EVS3/ecf/aqm/stats/jevs_aqm_stats.ecf
17052807.cbqs01
++ sleep 120
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=01 /lfs/h2/emc/vpppg/save/perry.shafran/EVS3/ecf/aqm/stats/jevs_aqm_stats.ecf
17052921.cbqs01
++ sleep 120
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=02 /lfs/h2/emc/vpppg/save/perry.shafran/EVS3/ecf/aqm/stats/jevs_aqm_stats.ecf
17053033.cbqs01
++ sleep 120
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=03 /lfs/h2/emc/vpppg/save/perry.shafran/EVS3/ecf/aqm/stats/jevs_aqm_stats.ecf
17053212.cbqs01
++ sleep 120
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=04 /lfs/h2/emc/vpppg/save/perry.shafran/EVS3/ecf/aqm/stats/jevs_aqm_stats.ecf
17053272.cbqs01
++ sleep 120
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=05 /lfs/h2/emc/vpppg/save/perry.shafran/EVS3/ecf/aqm/stats/jevs_aqm_stats.ecf
17053330.cbqs01
++ sleep 120
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=06 /lfs/h2/emc/vpppg/save/perry.shafran/EVS3/ecf/aqm/stats/jevs_aqm_stats.ecf
17053431.cbqs01
++ sleep 120
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=07 /lfs/h2/emc/vpppg/save/perry.shafran/EVS3/ecf/aqm/stats/jevs_aqm_stats.ecf
17053592.cbqs01
++ sleep 120
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=08 /lfs/h2/emc/vpppg/save/perry.shafran/EVS3/ecf/aqm/stats/jevs_aqm_stats.ecf
17053709.cbqs01
++ sleep 120
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=09 /lfs/h2/emc/vpppg/save/perry.shafran/EVS3/ecf/aqm/stats/jevs_aqm_stats.ecf
17053810.cbqs01
++ sleep 120
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=10 /lfs/h2/emc/vpppg/save/perry.shafran/EVS3/ecf/aqm/stats/jevs_aqm_stats.ecf
17053916.cbqs01
++ sleep 120
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=11 /lfs/h2/emc/vpppg/save/perry.shafran/EVS3/ecf/aqm/stats/jevs_aqm_stats.ecf
17054006.cbqs01
++ sleep 120
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=12 /lfs/h2/emc/vpppg/save/perry.shafran/EVS3/ecf/aqm/stats/jevs_aqm_stats.ecf
17054140.cbqs01
++ sleep 120
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=13 /lfs/h2/emc/vpppg/save/perry.shafran/EVS3/ecf/aqm/stats/jevs_aqm_stats.ecf
17054300.cbqs01
++ sleep 120
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=14 /lfs/h2/emc/vpppg/save/perry.shafran/EVS3/ecf/aqm/stats/jevs_aqm_stats.ecf
17054407.cbqs01
++ sleep 120
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=15 /lfs/h2/emc/vpppg/save/perry.shafran/EVS3/ecf/aqm/stats/jevs_aqm_stats.ecf
17054449.cbqs01
++ sleep 120
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=16 /lfs/h2/emc/vpppg/save/perry.shafran/EVS3/ecf/aqm/stats/jevs_aqm_stats.ecf
17054558.cbqs01
++ sleep 120
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=17 /lfs/h2/emc/vpppg/save/perry.shafran/EVS3/ecf/aqm/stats/jevs_aqm_stats.ecf
17054714.cbqs01
++ sleep 120
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=18 /lfs/h2/emc/vpppg/save/perry.shafran/EVS3/ecf/aqm/stats/jevs_aqm_stats.ecf
17055149.cbqs01
++ sleep 120
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=19 /lfs/h2/emc/vpppg/save/perry.shafran/EVS3/ecf/aqm/stats/jevs_aqm_stats.ecf
17055232.cbqs01
++ sleep 120
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=20 /lfs/h2/emc/vpppg/save/perry.shafran/EVS3/ecf/aqm/stats/jevs_aqm_stats.ecf
17055312.cbqs01
++ sleep 120
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=21 /lfs/h2/emc/vpppg/save/perry.shafran/EVS3/ecf/aqm/stats/jevs_aqm_stats.ecf
17055380.cbqs01
++ sleep 120
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=22 /lfs/h2/emc/vpppg/save/perry.shafran/EVS3/ecf/aqm/stats/jevs_aqm_stats.ecf
17055499.cbqs01
++ sleep 120
++ for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
++ export fhr
++ qsub -v cyc=23 /lfs/h2/emc/vpppg/save/perry.shafran/EVS3/ecf/aqm/stats/jevs_aqm_stats.ecf
17055613.cbqs01
++ sleep 120
++ exit
Job 17052798.cbqs01 - Epilogue complete. Execution time: 2 seconds
==================================================================
BEGIN - DEBUG INFO
==================================================================
Job 17052798.cbqs01 - Post Job Mem Usage:
nid001703: 2022-10-28.11 1 ===========================================
nid001703: 2022-10-28.11 2 #### Node Memory Usage for nid001703 ####
nid001703: 2022-10-28.11 3 ------------------
nid001703: 2022-10-28.11 4 Mem: total:527077116 used:8236604 free:516535748 shared:929124 cache:2304764 avail:515840632
nid001703: 2022-10-28.11 5 4.0K	/dev/shm
nid001703: 2022-10-28.11 6 3.6M	/tmp
nid001703: 2022-10-28.11 7 ===========================================
nid001703: 2022-10-28.41 1 ===========================================
nid001703: 2022-10-28.41 2 #### Node Memory Usage for nid001703 ####
nid001703: 2022-10-28.41 3 ------------------
nid001703: 2022-10-28.41 4 Mem: total:527077116 used:8111536 free:516601904 shared:930288 cache:2363676 avail:515936348
nid001703: 2022-10-28.41 5 4.0K	/dev/shm
nid001703: 2022-10-28.41 6 3.6M	/tmp
nid001703: 2022-10-28.41 7 ===========================================

------------------------------------------------------------------
Job 17052798.cbqs01 - /var/log/messages for job duration:
nid001703: 2022-10-28A--:--:--.------+--:-- nid001703 #### nid001703 - Job 17052798.cbqs01 Runtime Data from /var/log/messages
nid001703: 2022-10-28T19:24:10.521360+00:00 nid001703 prologue: MARK: Job 17052798.cbqs01 Start
nid001703: 2022-10-28T19:24:10.525485+00:00 nid001703 prologue: Job 17052798.cbqs01 nodelist: nid001703
nid001703: 2022-10-28T19:24:10.526557+00:00 nid001703 prologue: Job 17052798.cbqs01 - Checking existing ASLR settings...
nid001703: 2022-10-28T19:24:10.531286+00:00 nid001703 prologue: Job 17052798.cbqs01 - Checking palsd open file count...
nid001703: 2022-10-28T19:24:10.627784+00:00 nid001703 PBS_CMD: root : /opt/pbs/bin/qstat -Bf
nid001703: 2022-10-28T19:24:11.629972+00:00 nid001703 systemd[1]: session-31242.scope: Succeeded.
nid001703: 2022-10-28T19:24:11.852334+00:00 nid001703 prologue: Job 17052798.cbqs01 - Checking one-shot control: False
nid001703: 2022-10-28T19:24:11.853396+00:00 nid001703 prologue: Job 17052798.cbqs01 - Recording pre-job HSN counters...
nid001703: 2022-10-28T19:24:11.956784+00:00 nid001703 prologue: Job 17052798.cbqs01 - Recording pre-job memory usage...
nid001703: 2022-10-28T19:24:11.979406+00:00 nid001703 prologue: Job 17052798.cbqs01 - Killing any stray user processes...
nid001703: 2022-10-28T19:24:12.050118+00:00 nid001703 prologue: Job 17052798.cbqs01 - Enabling turboboost...
nid001703: 2022-10-28T19:24:12.052556+00:00 nid001703 prologue: Job 17052798.cbqs01 - Verifying post-boot workarounds...
nid001703: 2022-10-28T19:24:12.369585+00:00 nid001703 prologue: Job 17052798.cbqs01 - Warchk Complete
nid001703: 2022-10-28T19:24:12.370670+00:00 nid001703 prologue: Job 17052798.cbqs01 - Recording initial NFS client statistics...
nid001703: 2022-10-28T19:24:12.377130+00:00 nid001703 prologue: Job 17052798.cbqs01 - Prologue complete. Execution time: 3 seconds
nid001703: 2022-10-28T19:24:19.999414+00:00 nid001703 systemd[1]: session-31243.scope: Succeeded.
nid001703: 2022-10-28T19:24:51.515492+00:00 nid001703 systemd[1]: session-31244.scope: Succeeded.
nid001703: 2022-10-28T19:24:59.899445+00:00 nid001703 systemd[1]: session-31245.scope: Succeeded.
nid001703: 2022-10-28T19:25:31.488391+00:00 nid001703 systemd[1]: session-31246.scope: Succeeded.
nid001703: 2022-10-28T19:25:39.876015+00:00 nid001703 systemd[1]: session-31247.scope: Succeeded.
nid001703: 2022-10-28T19:26:11.760742+00:00 nid001703 systemd[1]: session-31248.scope: Succeeded.
nid001703: 2022-10-28T19:26:20.177090+00:00 nid001703 systemd[1]: session-31249.scope: Succeeded.
nid001703: 2022-10-28T19:26:46.502057+00:00 nid001703 systemd[1]: session-31250.scope: Succeeded.
nid001703: 2022-10-28T19:26:54.864989+00:00 nid001703 systemd[1]: session-31251.scope: Succeeded.
nid001703: 2022-10-28T19:27:26.506487+00:00 nid001703 systemd[1]: session-31252.scope: Succeeded.
nid001703: 2022-10-28T19:27:34.887487+00:00 nid001703 systemd[1]: session-31253.scope: Succeeded.
nid001703: 2022-10-28T19:28:06.559690+00:00 nid001703 systemd[1]: session-31254.scope: Succeeded.
nid001703: 2022-10-28T19:28:14.904055+00:00 nid001703 systemd[1]: session-31255.scope: Succeeded.
nid001703: 2022-10-28T19:28:46.613644+00:00 nid001703 systemd[1]: session-31256.scope: Succeeded.
nid001703: 2022-10-28T19:28:54.909030+00:00 nid001703 systemd[1]: session-31257.scope: Succeeded.
nid001703: 2022-10-28T19:29:27.199156+00:00 nid001703 systemd[1]: session-31258.scope: Succeeded.
nid001703: 2022-10-28T19:29:35.748637+00:00 nid001703 systemd[1]: session-31259.scope: Succeeded.
nid001703: 2022-10-28T19:30:01.513001+00:00 nid001703 systemd[1]: session-31260.scope: Succeeded.
nid001703: 2022-10-28T19:30:09.857239+00:00 nid001703 systemd[1]: session-31261.scope: Succeeded.
nid001703: 2022-10-28T19:30:56.696012+00:00 nid001703 systemd[1]: session-31262.scope: Succeeded.
nid001703: 2022-10-28T19:31:05.084338+00:00 nid001703 systemd[1]: session-31263.scope: Succeeded.
nid001703: 2022-10-28T19:31:36.759446+00:00 nid001703 systemd[1]: session-31264.scope: Succeeded.
nid001703: 2022-10-28T19:31:45.219126+00:00 nid001703 systemd[1]: session-31265.scope: Succeeded.
nid001703: 2022-10-28T19:32:11.675247+00:00 nid001703 systemd[1]: session-31266.scope: Succeeded.
nid001703: 2022-10-28T19:32:19.958841+00:00 nid001703 systemd[1]: session-31267.scope: Succeeded.
nid001703: 2022-10-28T19:32:35.093765+00:00 nid001703 systemd[1]: etc_update.service: Succeeded.
nid001703: 2022-10-28T19:32:51.536227+00:00 nid001703 systemd[1]: session-31268.scope: Succeeded.
nid001703: 2022-10-28T19:32:59.927970+00:00 nid001703 systemd[1]: session-31269.scope: Succeeded.
nid001703: 2022-10-28T19:33:31.703729+00:00 nid001703 systemd[1]: session-31270.scope: Succeeded.
nid001703: 2022-10-28T19:33:40.083618+00:00 nid001703 systemd[1]: session-31271.scope: Succeeded.
nid001703: 2022-10-28T19:34:12.053599+00:00 nid001703 systemd[1]: session-31272.scope: Succeeded.
nid001703: 2022-10-28T19:34:20.371724+00:00 nid001703 systemd[1]: session-31273.scope: Succeeded.
nid001703: 2022-10-28T19:34:51.499676+00:00 nid001703 systemd[1]: session-31274.scope: Succeeded.
nid001703: 2022-10-28T19:34:59.898714+00:00 nid001703 systemd[1]: session-31275.scope: Succeeded.
nid001703: 2022-10-28T19:35:31.543287+00:00 nid001703 systemd[1]: session-31276.scope: Succeeded.
nid001703: 2022-10-28T19:35:39.921605+00:00 nid001703 systemd[1]: session-31277.scope: Succeeded.
nid001703: 2022-10-28T19:36:11.711232+00:00 nid001703 systemd[1]: session-31278.scope: Succeeded.
nid001703: 2022-10-28T19:36:20.116455+00:00 nid001703 systemd[1]: session-31279.scope: Succeeded.
nid001703: 2022-10-28T19:36:51.581657+00:00 nid001703 systemd[1]: session-31280.scope: Succeeded.
nid001703: 2022-10-28T19:36:59.972479+00:00 nid001703 systemd[1]: session-31281.scope: Succeeded.
nid001703: 2022-10-28T19:37:31.555995+00:00 nid001703 systemd[1]: session-31282.scope: Succeeded.
nid001703: 2022-10-28T19:37:39.943689+00:00 nid001703 systemd[1]: session-31283.scope: Succeeded.
nid001703: 2022-10-28T19:38:11.789567+00:00 nid001703 systemd[1]: session-31284.scope: Succeeded.
nid001703: 2022-10-28T19:38:20.218193+00:00 nid001703 systemd[1]: session-31285.scope: Succeeded.
nid001703: 2022-10-28T19:38:51.501956+00:00 nid001703 systemd[1]: session-31286.scope: Succeeded.
nid001703: 2022-10-28T19:38:59.839286+00:00 nid001703 systemd[1]: session-31287.scope: Succeeded.
nid001703: 2022-10-28T19:39:32.794868+00:00 nid001703 systemd[1]: session-31288.scope: Succeeded.
nid001703: 2022-10-28T19:39:41.708657+00:00 nid001703 systemd[1]: session-31289.scope: Succeeded.
nid001703: 2022-10-28T19:40:06.538798+00:00 nid001703 systemd[1]: session-31290.scope: Succeeded.
nid001703: 2022-10-28T19:40:14.841549+00:00 nid001703 systemd[1]: session-31291.scope: Succeeded.
nid001703: 2022-10-28T19:40:51.598920+00:00 nid001703 systemd[1]: session-31292.scope: Succeeded.
nid001703: 2022-10-28T19:40:59.977552+00:00 nid001703 systemd[1]: session-31293.scope: Succeeded.
nid001703: 2022-10-28T19:41:16.087694+00:00 nid001703 systemd[1]: etc_update.service: Succeeded.
nid001703: 2022-10-28T19:41:31.568825+00:00 nid001703 systemd[1]: session-31294.scope: Succeeded.
nid001703: 2022-10-28T19:41:39.961602+00:00 nid001703 systemd[1]: session-31295.scope: Succeeded.
nid001703: 2022-10-28T19:42:11.628810+00:00 nid001703 systemd[1]: session-31296.scope: Succeeded.
nid001703: 2022-10-28T19:42:20.004061+00:00 nid001703 systemd[1]: session-31297.scope: Succeeded.
nid001703: 2022-10-28T19:42:51.661624+00:00 nid001703 systemd[1]: session-31298.scope: Succeeded.
nid001703: 2022-10-28T19:43:00.039031+00:00 nid001703 systemd[1]: session-31299.scope: Succeeded.
nid001703: 2022-10-28T19:43:26.696663+00:00 nid001703 systemd[1]: session-31300.scope: Succeeded.
nid001703: 2022-10-28T19:43:35.067303+00:00 nid001703 systemd[1]: session-31301.scope: Succeeded.
nid001703: 2022-10-28T19:44:06.525858+00:00 nid001703 systemd[1]: session-31302.scope: Succeeded.
nid001703: 2022-10-28T19:44:14.911282+00:00 nid001703 systemd[1]: session-31303.scope: Succeeded.
nid001703: 2022-10-28T19:44:46.639409+00:00 nid001703 systemd[1]: session-31304.scope: Succeeded.
nid001703: 2022-10-28T19:44:55.053632+00:00 nid001703 systemd[1]: session-31305.scope: Succeeded.
nid001703: 2022-10-28T19:45:26.549820+00:00 nid001703 systemd[1]: session-31306.scope: Succeeded.
nid001703: 2022-10-28T19:45:34.932593+00:00 nid001703 systemd[1]: session-31307.scope: Succeeded.
nid001703: 2022-10-28T19:46:06.607178+00:00 nid001703 systemd[1]: session-31308.scope: Succeeded.
nid001703: 2022-10-28T19:46:15.006835+00:00 nid001703 systemd[1]: session-31309.scope: Succeeded.
nid001703: 2022-10-28T19:46:46.677467+00:00 nid001703 systemd[1]: session-31310.scope: Succeeded.
nid001703: 2022-10-28T19:46:55.046547+00:00 nid001703 systemd[1]: session-31311.scope: Succeeded.
nid001703: 2022-10-28T19:47:26.515681+00:00 nid001703 systemd[1]: session-31312.scope: Succeeded.
nid001703: 2022-10-28T19:47:34.888471+00:00 nid001703 systemd[1]: session-31313.scope: Succeeded.
nid001703: 2022-10-28T19:48:07.718786+00:00 nid001703 systemd[1]: session-31314.scope: Succeeded.
nid001703: 2022-10-28T19:48:16.683519+00:00 nid001703 systemd[1]: session-31315.scope: Succeeded.
nid001703: 2022-10-28T19:48:41.569222+00:00 nid001703 systemd[1]: session-31316.scope: Succeeded.
nid001703: 2022-10-28T19:48:49.949754+00:00 nid001703 systemd[1]: session-31317.scope: Succeeded.
nid001703: 2022-10-28T19:49:21.601155+00:00 nid001703 systemd[1]: session-31318.scope: Succeeded.
nid001703: 2022-10-28T19:49:30.061638+00:00 nid001703 systemd[1]: session-31319.scope: Succeeded.
nid001703: 2022-10-28T19:50:01.613721+00:00 nid001703 systemd[1]: session-31320.scope: Succeeded.
nid001703: 2022-10-28T19:50:09.987349+00:00 nid001703 systemd[1]: session-31321.scope: Succeeded.
nid001703: 2022-10-28T19:50:56.462003+00:00 nid001703 systemd[1]: session-31322.scope: Succeeded.
nid001703: 2022-10-28T19:51:04.864330+00:00 nid001703 systemd[1]: session-31323.scope: Succeeded.
nid001703: 2022-10-28T19:51:36.498675+00:00 nid001703 systemd[1]: session-31324.scope: Succeeded.
nid001703: 2022-10-28T19:51:44.897930+00:00 nid001703 systemd[1]: session-31325.scope: Succeeded.
nid001703: 2022-10-28T19:52:16.817790+00:00 nid001703 systemd[1]: session-31326.scope: Succeeded.
nid001703: 2022-10-28T19:52:25.202392+00:00 nid001703 systemd[1]: session-31327.scope: Succeeded.
nid001703: 2022-10-28T19:52:56.487422+00:00 nid001703 systemd[1]: session-31328.scope: Succeeded.
nid001703: 2022-10-28T19:53:04.580550+00:00 nid001703 systemd[1]: etc_update.service: Succeeded.
nid001703: 2022-10-28T19:53:04.871775+00:00 nid001703 systemd[1]: session-31329.scope: Succeeded.
nid001703: 2022-10-28T19:53:36.549899+00:00 nid001703 systemd[1]: session-31330.scope: Succeeded.
nid001703: 2022-10-28T19:53:44.962148+00:00 nid001703 systemd[1]: session-31331.scope: Succeeded.
nid001703: 2022-10-28T19:54:16.533561+00:00 nid001703 systemd[1]: session-31332.scope: Succeeded.
nid001703: 2022-10-28T19:54:24.927588+00:00 nid001703 systemd[1]: session-31333.scope: Succeeded.
nid001703: 2022-10-28T19:54:56.611683+00:00 nid001703 systemd[1]: session-31334.scope: Succeeded.
nid001703: 2022-10-28T19:55:04.974867+00:00 nid001703 systemd[1]: session-31335.scope: Succeeded.
nid001703: 2022-10-28T19:55:36.527394+00:00 nid001703 systemd[1]: session-31336.scope: Succeeded.
nid001703: 2022-10-28T19:55:44.915175+00:00 nid001703 systemd[1]: session-31337.scope: Succeeded.
nid001703: 2022-10-28T19:56:16.579082+00:00 nid001703 systemd[1]: session-31338.scope: Succeeded.
nid001703: 2022-10-28T19:56:24.967908+00:00 nid001703 systemd[1]: session-31339.scope: Succeeded.
nid001703: 2022-10-28T19:56:56.551124+00:00 nid001703 systemd[1]: session-31340.scope: Succeeded.
nid001703: 2022-10-28T19:57:04.847568+00:00 nid001703 systemd[1]: session-31341.scope: Succeeded.
nid001703: 2022-10-28T19:57:36.515926+00:00 nid001703 systemd[1]: session-31342.scope: Succeeded.
nid001703: 2022-10-28T19:57:44.851998+00:00 nid001703 systemd[1]: session-31343.scope: Succeeded.
nid001703: 2022-10-28T19:58:16.521807+00:00 nid001703 systemd[1]: session-31344.scope: Succeeded.
nid001703: 2022-10-28T19:58:24.879479+00:00 nid001703 systemd[1]: session-31345.scope: Succeeded.
nid001703: 2022-10-28T19:58:56.969359+00:00 nid001703 systemd[1]: session-31346.scope: Succeeded.
nid001703: 2022-10-28T19:59:05.453102+00:00 nid001703 systemd[1]: session-31347.scope: Succeeded.
nid001703: 2022-10-28T19:59:31.513383+00:00 nid001703 systemd[1]: session-31348.scope: Succeeded.
nid001703: 2022-10-28T19:59:39.861002+00:00 nid001703 systemd[1]: session-31349.scope: Succeeded.
nid001703: 2022-10-28T20:00:14.413987+00:00 nid001703 systemd[1]: Started Timeline of Snapper Snapshots.
nid001703: 2022-10-28T20:00:14.595958+00:00 nid001703 dbus-daemon[5549]: [system] Activating via systemd: service name='org.opensuse.Snapper' unit='snapperd.service' requested by ':1.63050' (uid=0 pid=15520 comm="/usr/lib/snapper/systemd-helper --timeline ")
nid001703: 2022-10-28T20:00:14.599572+00:00 nid001703 systemd[1]: Starting DBus interface for snapper...
nid001703: 2022-10-28T20:00:14.621647+00:00 nid001703 dbus-daemon[5549]: [system] Successfully activated service 'org.opensuse.Snapper'
nid001703: 2022-10-28T20:00:14.621766+00:00 nid001703 systemd[1]: Started DBus interface for snapper.
nid001703: 2022-10-28T20:00:14.627004+00:00 nid001703 systemd[1]: snapper-timeline.service: Succeeded.
nid001703: 2022-10-28T20:00:14.736242+00:00 nid001703 systemd[1]: session-31350.scope: Succeeded.
nid001703: 2022-10-28T20:00:23.073430+00:00 nid001703 systemd[1]: session-31351.scope: Succeeded.
nid001703: 2022-10-28T20:01:01.772269+00:00 nid001703 systemd[1]: session-31352.scope: Succeeded.
nid001703: 2022-10-28T20:01:10.341499+00:00 nid001703 systemd[1]: session-31353.scope: Succeeded.
nid001703: 2022-10-28T20:01:14.688674+00:00 nid001703 systemd[1]: snapperd.service: Succeeded.
nid001703: 2022-10-28T20:01:41.526131+00:00 nid001703 systemd[1]: session-31354.scope: Succeeded.
nid001703: 2022-10-28T20:01:49.868295+00:00 nid001703 systemd[1]: session-31355.scope: Succeeded.
nid001703: 2022-10-28T20:02:21.546541+00:00 nid001703 systemd[1]: session-31356.scope: Succeeded.
nid001703: 2022-10-28T20:02:29.615339+00:00 nid001703 systemd[1]: etc_update.service: Succeeded.
nid001703: 2022-10-28T20:02:29.905365+00:00 nid001703 systemd[1]: session-31357.scope: Succeeded.
nid001703: 2022-10-28T20:03:01.663362+00:00 nid001703 systemd[1]: session-31358.scope: Succeeded.
nid001703: 2022-10-28T20:03:10.039848+00:00 nid001703 systemd[1]: session-31359.scope: Succeeded.
nid001703: 2022-10-28T20:03:41.546405+00:00 nid001703 systemd[1]: session-31360.scope: Succeeded.
nid001703: 2022-10-28T20:03:49.924951+00:00 nid001703 systemd[1]: session-31361.scope: Succeeded.
nid001703: 2022-10-28T20:04:21.485631+00:00 nid001703 systemd[1]: session-31362.scope: Succeeded.
nid001703: 2022-10-28T20:04:29.840516+00:00 nid001703 systemd[1]: session-31363.scope: Succeeded.
nid001703: 2022-10-28T20:05:01.597543+00:00 nid001703 systemd[1]: session-31364.scope: Succeeded.
nid001703: 2022-10-28T20:05:09.996922+00:00 nid001703 systemd[1]: session-31365.scope: Succeeded.
nid001703: 2022-10-28T20:05:41.631338+00:00 nid001703 systemd[1]: session-31366.scope: Succeeded.
nid001703: 2022-10-28T20:05:50.067105+00:00 nid001703 systemd[1]: session-31367.scope: Succeeded.
nid001703: 2022-10-28T20:06:21.950510+00:00 nid001703 systemd[1]: session-31368.scope: Succeeded.
nid001703: 2022-10-28T20:06:30.735903+00:00 nid001703 systemd[1]: session-31369.scope: Succeeded.
nid001703: 2022-10-28T20:06:56.471095+00:00 nid001703 systemd[1]: session-31370.scope: Succeeded.
nid001703: 2022-10-28T20:07:04.816394+00:00 nid001703 systemd[1]: session-31371.scope: Succeeded.
nid001703: 2022-10-28T20:07:37.203473+00:00 nid001703 systemd[1]: session-31372.scope: Succeeded.
nid001703: 2022-10-28T20:07:46.483455+00:00 nid001703 systemd[1]: session-31373.scope: Succeeded.
nid001703: 2022-10-28T20:08:12.093499+00:00 nid001703 systemd[1]: session-31374.scope: Succeeded.
nid001703: 2022-10-28T20:08:20.450549+00:00 nid001703 systemd[1]: session-31375.scope: Succeeded.
nid001703: 2022-10-28T20:08:51.600182+00:00 nid001703 systemd[1]: session-31376.scope: Succeeded.
nid001703: 2022-10-28T20:08:59.989603+00:00 nid001703 systemd[1]: session-31377.scope: Succeeded.
nid001703: 2022-10-28T20:09:32.122645+00:00 nid001703 systemd[1]: session-31378.scope: Succeeded.
nid001703: 2022-10-28T20:09:40.833304+00:00 nid001703 systemd[1]: session-31379.scope: Succeeded.
nid001703: 2022-10-28T20:10:06.515656+00:00 nid001703 systemd[1]: session-31380.scope: Succeeded.
nid001703: 2022-10-28T20:10:14.911649+00:00 nid001703 systemd[1]: session-31381.scope: Succeeded.
nid001703: 2022-10-28T20:10:51.573876+00:00 nid001703 systemd[1]: session-31382.scope: Succeeded.
nid001703: 2022-10-28T20:10:59.909787+00:00 nid001703 systemd[1]: session-31383.scope: Succeeded.
nid001703: 2022-10-28T20:11:31.689531+00:00 nid001703 systemd[1]: session-31384.scope: Succeeded.
nid001703: 2022-10-28T20:11:40.067644+00:00 nid001703 systemd[1]: session-31385.scope: Succeeded.
nid001703: 2022-10-28T20:11:44.088297+00:00 nid001703 systemd[1]: etc_update.service: Succeeded.
nid001703: 2022-10-28T20:12:11.525569+00:00 nid001703 systemd[1]: session-31386.scope: Succeeded.
nid001703: 2022-10-28T20:12:19.912844+00:00 nid001703 systemd[1]: session-31387.scope: Succeeded.
nid001703: 2022-10-28T20:12:40.947834+00:00 nid001703 epilogue: Job 17052798.cbqs01 complete, running post-job actions.
nid001703: 2022-10-28T20:12:40.966007+00:00 nid001703 epilogue: Job 17052798.cbqs01 - Recording post-job HSN counters...
nid001703: 2022-10-28T20:12:41.074539+00:00 nid001703 epilogue: Job 17052798.cbqs01 - Recording post-job memory usage...
nid001703: 2022-10-28T20:12:41.090714+00:00 nid001703 epilogue: Job 17052798.cbqs01 - Recording job NFS statistics to /tmp/nfsstats.17052798.cbqs01
nid001703: 2022-10-28T20:12:41.577568+00:00 nid001703 epilogue: Job 17052798.cbqs01 - Clearing /tmp...
nid001703: 2022-10-28T20:12:41.592026+00:00 nid001703 epilogue: Job 17052798.cbqs01 - Clearing shared memory...
nid001703: 2022-10-28T20:12:41.604155+00:00 nid001703 epilogue: Job 17052798.cbqs01 - Clearing memory cache...
nid001703: 2022-10-28T20:12:41.796981+00:00 nid001703 kernel: [532058.294734] drop_caches (18528): drop_caches: 3
nid001703: 2022-10-28T20:12:41.928892+00:00 nid001703 epilogue: Job 17052798.cbqs01 - Releasing Lustre Locks...
nid001703: 2022-10-28T20:12:41.948229+00:00 nid001703 epilogue: MARK: Job 17052798.cbqs01 Complete.

------------------------------------------------------------------
Job 17052798.cbqs01 - dmesg output for job duration:
nid001703: 2022-10-28A--:--:--.------+--:-- nid001703 #### nid001703 - Job 17052798.cbqs01 Runtime Data from dmesg
nid001703: [Fri Oct 28 19:23:51 2022] MARK: Job 17052798.cbqs01 Start
nid001703: [Fri Oct 28 20:12:22 2022] MARK: Job 17052798.cbqs01 Complete.
nid001703: [Fri Oct 28 20:12:22 2022] drop_caches (18528): drop_caches: 3

------------------------------------------------------------------
Job 17052798.cbqs01 - Pre/Post job diff on HSN (MLX) Counters:
nid001703: 2022-10-28A--:--:--.------+--:-- nid001703 #### nid001703 - Job 17052798.cbqs01 HSN0 MLX Counter Post-Job Difference
nid001703: multicast: 438245					      |	multicast: 438474
nid001703: port_rcv_data: 36883128698766				      |	port_rcv_data: 36883129317324
nid001703: port_rcv_packets: 54360733557				      |	port_rcv_packets: 54360746184
nid001703: port_xmit_data: 36716670255685				      |	port_xmit_data: 36716670891209
nid001703: port_xmit_packets: 54525052709				      |	port_xmit_packets: 54525065349
nid001703: rx_bytes: 44204601222					      |	rx_bytes: 44215846809
nid001703: rx_packets: 23142255					      |	rx_packets: 23162192
nid001703: tx_bytes: 38361601056					      |	tx_bytes: 38365192049
nid001703: tx_packets: 17259615					      |	tx_packets: 17283955
nid001703: unicast_rcv_packets: 54360733557			      |	unicast_rcv_packets: 54360746184
nid001703: unicast_xmit_packets: 54525052709			      |	unicast_xmit_packets: 54525065349

------------------------------------------------------------------
### Job 17052798.cbqs01 - NFS Statistics for job duration:
nid001703: #### 2022-10-28.00 #### nid001703 - Job 17052798.cbqs01 NFS Statistics for job duration (nfsstat)
nid001703: ## /usr/sbin/nfsstat -v -S /tmp/nfsstats.begin.17052798.cbqs01 :
nid001703: Client packet stats:
nid001703: packets    udp        tcp        tcpconn
nid001703: 0          0          0          0       
nid001703: 
nid001703: Client rpc stats:
nid001703: calls      retrans    authrefrsh
nid001703: 13838      0          13838   
nid001703: 
nid001703: Client nfs v3:
nid001703: null             getattr          setattr          lookup           access           
nid001703: 0         0%     12681    91%     5         0%     313       2%     312       2%     
nid001703: readlink         read             write            create           mkdir            
nid001703: 42        0%     137       0%     86        0%     0         0%     0         0%     
nid001703: symlink          mknod            remove           rmdir            rename           
nid001703: 0         0%     0         0%     0         0%     0         0%     0         0%     
nid001703: link             readdir          readdirplus      fsstat           fsinfo           
nid001703: 0         0%     0         0%     262       1%     0         0%     0         0%     
nid001703: pathconf         commit           
nid001703: 0         0%     0         0%     
nid001703: 
nid001703: 
nid001703: -----------------------------------------------------------------------------------
nid001703: 
nid001703: #### 2022-10-28.00 #### nid001703 - Job 17052798.cbqs01 NFS Mount Statistics for job duration (mountstats)
nid001703: ## /usr/sbin/mountstats iostat -S /tmp/mntstats.begin.17052798.cbqs01 /apps :
nid001703: 
nid001703: 
nid001703: 172.20.250.16:/AZ-HFS-Cactus-apps mounted on /apps:
nid001703: 
nid001703:            ops/s       rpc bklog
nid001703:            4.344           0.000
nid001703: 
nid001703: read:              ops/s            kB/s           kB/op         retrans    avg RTT (ms)    avg exe (ms)
nid001703:                    0.016           0.034           2.127        0 (0.0%)           0.174           0.217
nid001703: write:             ops/s            kB/s           kB/op         retrans    avg RTT (ms)    avg exe (ms)
nid001703:                    0.000           0.000           0.000        0 (0.0%)           0.000           0.000
nid001703: ## /usr/sbin/mountstats iostat -S /tmp/mntstats.begin.17052798.cbqs01 /sfs :
nid001703: 
nid001703: 
nid001703: 172.20.250.16:/AZ-HFS-Cactus-sfs mounted on /sfs:
nid001703: 
nid001703:            ops/s       rpc bklog
nid001703:            4.344           0.000
nid001703: 
nid001703: read:              ops/s            kB/s           kB/op         retrans    avg RTT (ms)    avg exe (ms)
nid001703:                    0.001           0.002           2.223        0 (0.0%)           0.000           0.500
nid001703: write:             ops/s            kB/s           kB/op         retrans    avg RTT (ms)    avg exe (ms)
nid001703:                    0.030           0.073           2.480        0 (0.0%)           2.081           2.163
nid001703: ## /usr/sbin/mountstats iostat -S /tmp/mntstats.begin.17052798.cbqs01 /u :
nid001703: 
nid001703: 
nid001703: 172.20.250.17:/AZ-HFS-Cactus-u mounted on /u:
nid001703: 
nid001703:            ops/s       rpc bklog
nid001703:            0.030           0.000
nid001703: 
nid001703: read:              ops/s            kB/s           kB/op         retrans    avg RTT (ms)    avg exe (ms)
nid001703:                    0.000           0.000           0.969        0 (0.0%)           1.000           1.000
nid001703: write:             ops/s            kB/s           kB/op         retrans    avg RTT (ms)    avg exe (ms)
nid001703:                    0.000           0.000           0.000        0 (0.0%)           0.000           0.000
nid001703: ## /usr/sbin/mountstats iostat -S /tmp/mntstats.begin.17052798.cbqs01 /pe :
nid001703: 
nid001703: 
nid001703: 10.31.62.247:/cm_shared/image/images_rw_nfs/pe mounted on /pe:
nid001703: 
nid001703:            ops/s       rpc bklog
nid001703:            0.422           0.000
nid001703: 
nid001703: read:              ops/s            kB/s           kB/op         retrans    avg RTT (ms)    avg exe (ms)
nid001703:                    0.003           0.287          92.624        0 (0.0%)           3.222           3.333
nid001703: write:             ops/s            kB/s           kB/op         retrans    avg RTT (ms)    avg exe (ms)
nid001703:                    0.000           0.000           0.000        0 (0.0%)           0.000           0.000
nid001703: ----------------
nid001703: ## /usr/sbin/mountstats mountstats -S /tmp/mntstats.begin.17052798.cbqs01 /apps :
nid001703: Stats for 172.20.250.16:/AZ-HFS-Cactus-apps mounted on /apps:
nid001703:   NFS mount options: ro,vers=3,rsize=65536,wsize=65536,namlen=255,acregmin=3,acregmax=60,acdirmin=30,acdirmax=60,hard,proto=tcp,timeo=600,retrans=2,sec=sys,mountaddr=172.20.250.16,mountvers=3,mountport=4048,mountproto=udp,local_lock=none
nid001703:   NFS server capabilities: caps=0x3fc7,wtmult=4096,dtsize=8192,bsize=0,namlen=255
nid001703:   NFS security flavor: 1  pseudoflavor: 0
nid001703: 
nid001703: NFS byte counts:
nid001703:   applications read 10264564 bytes via read(2)
nid001703:   applications wrote 0 bytes via write(2)
nid001703:   applications read 0 bytes via O_DIRECT read(2)
nid001703:   applications wrote 0 bytes via O_DIRECT write(2)
nid001703:   client read 86870 bytes via NFS READ
nid001703:   client wrote 0 bytes via NFS WRITE
nid001703: 
nid001703: RPC statistics:
nid001703:   12637 RPC requests sent, 12637 RPC replies received (0 XIDs not found)
nid001703:   average backlog queue length: 0
nid001703: 
nid001703: GETATTR:
nid001703: 	11646 ops (92%) 
nid001703: 	avg bytes sent per op: avg bytes received per op: 112
nid001703: 	backlog wait: 0.001975 	RTT: 0.225571 	total execute time: 0.236390 (milliseconds)
nid001703: READDIRPLUS:
nid001703: 	262 ops (2%) 
nid001703: 	avg bytes sent per op: avg bytes received per op: 944
nid001703: 	backlog wait: 0.003817 	RTT: 0.187023 	total execute time: 0.202290 (milliseconds)
nid001703: ACCESS:
nid001703: 	246 ops (1%) 
nid001703: 	avg bytes sent per op: avg bytes received per op: 120
nid001703: 	backlog wait: 0.004065 	RTT: 0.256098 	total execute time: 0.264228 (milliseconds)
nid001703: LOOKUP:
nid001703: 	137 ops (1%) 
nid001703: 	avg bytes sent per op: avg bytes received per op: 160
nid001703: 	backlog wait: 0.000000 	RTT: 0.102190 	total execute time: 0.109489 (milliseconds)
nid001703: READ:
nid001703: 	46 ops (0%) 
nid001703: 	avg bytes sent per op: avg bytes received per op: 2018
nid001703: 	backlog wait: 0.021739 	RTT: 0.173913 	total execute time: 0.217391 (milliseconds)
nid001703: READLINK:
nid001703: 	40 ops (0%) 
nid001703: 	avg bytes sent per op: avg bytes received per op: 132
nid001703: 	backlog wait: 0.000000 	RTT: 0.075000 	total execute time: 0.100000 (milliseconds)
nid001703: 
nid001703: ## /usr/sbin/mountstats mountstats -S /tmp/mntstats.begin.17052798.cbqs01 /sfs :
nid001703: 
nid001703: Stats for 172.20.250.16:/AZ-HFS-Cactus-sfs mounted on /sfs:
nid001703:   NFS mount options: rw,vers=3,rsize=65536,wsize=65536,namlen=255,acregmin=3,acregmax=60,acdirmin=30,acdirmax=60,hard,proto=tcp,timeo=600,retrans=2,sec=sys,mountaddr=172.20.250.16,mountvers=3,mountport=4048,mountproto=udp,local_lock=none
nid001703:   NFS server capabilities: caps=0x3fc7,wtmult=4096,dtsize=8192,bsize=0,namlen=255
nid001703:   NFS security flavor: 1  pseudoflavor: 0
nid001703: 
nid001703: NFS byte counts:
nid001703:   applications read 14285 bytes via read(2)
nid001703:   applications wrote 20373 bytes via write(2)
nid001703:   applications read 0 bytes via O_DIRECT read(2)
nid001703:   applications wrote 0 bytes via O_DIRECT write(2)
nid001703:   client read 4040 bytes via NFS READ
nid001703:   client wrote 192872 bytes via NFS WRITE
nid001703: 
nid001703: RPC statistics:
nid001703:   12637 RPC requests sent, 12637 RPC replies received (0 XIDs not found)
nid001703:   average backlog queue length: 0
nid001703: 
nid001703: GETATTR:
nid001703: 	156 ops (1%) 
nid001703: 	avg bytes sent per op: avg bytes received per op: 112
nid001703: 	backlog wait: 0.000000 	RTT: 0.147436 	total execute time: 0.185897 (milliseconds)
nid001703: WRITE:
nid001703: 	86 ops (0%) 
nid001703: 	avg bytes sent per op: avg bytes received per op: 160
nid001703: 	backlog wait: 0.034884 	RTT: 2.081395 	total execute time: 2.162791 (milliseconds)
nid001703: ACCESS:
nid001703: 	6 ops (0%) 
nid001703: 	avg bytes sent per op: avg bytes received per op: 120
nid001703: 	backlog wait: 0.000000 	RTT: 0.500000 	total execute time: 0.333333 (milliseconds)
nid001703: SETATTR:
nid001703: 	5 ops (0%) 
nid001703: 	avg bytes sent per op: avg bytes received per op: 144
nid001703: 	backlog wait: 0.000000 	RTT: 0.600000 	total execute time: 0.400000 (milliseconds)
nid001703: LOOKUP:
nid001703: 	5 ops (0%) 
nid001703: 	avg bytes sent per op: avg bytes received per op: 240
nid001703: 	backlog wait: 0.000000 	RTT: 0.200000 	total execute time: 0.200000 (milliseconds)
nid001703: READ:
nid001703: 	2 ops (0%) 
nid001703: 	avg bytes sent per op: avg bytes received per op: 2150
nid001703: 	backlog wait: 0.000000 	RTT: 0.000000 	total execute time: 0.500000 (milliseconds)
nid001703: 
nid001703: ## /usr/sbin/mountstats mountstats -S /tmp/mntstats.begin.17052798.cbqs01 /u :
nid001703: 
nid001703: Stats for 172.20.250.17:/AZ-HFS-Cactus-u mounted on /u:
nid001703:   NFS mount options: rw,vers=3,rsize=65536,wsize=65536,namlen=255,acregmin=3,acregmax=60,acdirmin=30,acdirmax=60,hard,proto=tcp,timeo=600,retrans=2,sec=sys,mountaddr=172.20.250.17,mountvers=3,mountport=4048,mountproto=udp,local_lock=none
nid001703:   NFS server capabilities: caps=0x3fc7,wtmult=4096,dtsize=8192,bsize=0,namlen=255
nid001703:   NFS security flavor: 1  pseudoflavor: 0
nid001703: 
nid001703: NFS byte counts:
nid001703:   applications read 701 bytes via read(2)
nid001703:   applications wrote 0 bytes via write(2)
nid001703:   applications read 0 bytes via O_DIRECT read(2)
nid001703:   applications wrote 0 bytes via O_DIRECT write(2)
nid001703:   client read 701 bytes via NFS READ
nid001703:   client wrote 0 bytes via NFS WRITE
nid001703: 
nid001703: RPC statistics:
nid001703:   87 RPC requests sent, 87 RPC replies received (0 XIDs not found)
nid001703:   average backlog queue length: 0
nid001703: 
nid001703: GETATTR:
nid001703: 	48 ops (55%) 
nid001703: 	avg bytes sent per op: avg bytes received per op: 112
nid001703: 	backlog wait: 0.000000 	RTT: 0.208333 	total execute time: 0.229167 (milliseconds)
nid001703: ACCESS:
nid001703: 	26 ops (29%) 
nid001703: 	avg bytes sent per op: avg bytes received per op: 120
nid001703: 	backlog wait: 0.000000 	RTT: 0.153846 	total execute time: 0.153846 (milliseconds)
nid001703: LOOKUP:
nid001703: 	12 ops (13%) 
nid001703: 	avg bytes sent per op: avg bytes received per op: 136
nid001703: 	backlog wait: 0.000000 	RTT: 0.166667 	total execute time: 0.166667 (milliseconds)
nid001703: READ:
nid001703: 	1 ops (1%) 
nid001703: 	avg bytes sent per op: avg bytes received per op: 832
nid001703: 	backlog wait: 0.000000 	RTT: 1.000000 	total execute time: 1.000000 (milliseconds)
nid001703: 
nid001703: ## /usr/sbin/mountstats mountstats -S /tmp/mntstats.begin.17052798.cbqs01 /pe :
nid001703: 
nid001703: Stats for 10.31.62.247:/cm_shared/image/images_rw_nfs/pe mounted on /pe:
nid001703:   NFS mount options: ro,vers=3,rsize=1048576,wsize=1048576,namlen=255,acregmin=3,acregmax=60,acdirmin=30,acdirmax=60,hard,nolock,proto=tcp,timeo=600,retrans=2,sec=sys,mountaddr=10.31.62.247,mountvers=3,mountport=38465,mountproto=tcp,local_lock=all
nid001703:   NFS server capabilities: caps=0x3fcf,wtmult=4096,dtsize=32768,bsize=0,namlen=255
nid001703:   NFS security flavor: 1  pseudoflavor: 0
nid001703: 
nid001703: NFS byte counts:
nid001703:   applications read 103424 bytes via read(2)
nid001703:   applications wrote 0 bytes via write(2)
nid001703:   applications read 0 bytes via O_DIRECT read(2)
nid001703:   applications wrote 0 bytes via O_DIRECT write(2)
nid001703:   client read 851968 bytes via NFS READ
nid001703:   client wrote 0 bytes via NFS WRITE
nid001703: 
nid001703: RPC statistics:
nid001703:   1227 RPC requests sent, 1227 RPC replies received (0 XIDs not found)
nid001703:   average backlog queue length: 0
nid001703: 
nid001703: GETATTR:
nid001703: 	830 ops (67%) 
nid001703: 	avg bytes sent per op: avg bytes received per op: 112
nid001703: 	backlog wait: 0.002410 	RTT: 0.359036 	total execute time: 0.368675 (milliseconds)
nid001703: LOOKUP:
nid001703: 	159 ops (12%) 
nid001703: 	avg bytes sent per op: avg bytes received per op: 82
nid001703: 	backlog wait: 0.000000 	RTT: 0.547170 	total execute time: 0.559748 (milliseconds)
nid001703: ACCESS:
nid001703: 	34 ops (2%) 
nid001703: 	avg bytes sent per op: avg bytes received per op: 36
nid001703: 	backlog wait: 0.000000 	RTT: 0.352941 	total execute time: 0.352941 (milliseconds)
nid001703: READ:
nid001703: 	9 ops (0%) 
nid001703: 	avg bytes sent per op: avg bytes received per op: 94707
nid001703: 	backlog wait: 0.111111 	RTT: 3.222222 	total execute time: 3.333333 (milliseconds)
nid001703: READLINK:
nid001703: 	2 ops (0%) 
nid001703: 	avg bytes sent per op: avg bytes received per op: 136
nid001703: 	backlog wait: 0.000000 	RTT: 0.500000 	total execute time: 0.500000 (milliseconds)
nid001703: 
nid001703: 

------------------------------------------------------------------
### Job 17052798.cbqs01 - Exit status is 0

------------------------------------------------------------------
Job 17052798.cbqs01 - Job summary:
Job Id: 17052798.cbqs01
    Job_Name = run_aqm_stats
    Job_Owner = perry.shafran@clogin01.cactus.wcoss2.ncep.noaa.gov
    resources_used.cpupercent = 6
    resources_used.cput = 00:00:02
    resources_used.mem = 13612kb
    resources_used.ncpus = 1
    resources_used.vmem = 39364kb
    resources_used.walltime = 00:48:18
    job_state = R
    queue = dev
    server = cbqs01
    Account_Name = VERF-DEV
    Checkpoint = u
    ctime = Fri Oct 28 19:24:07 2022
    Error_Path = clogin01.cactus.wcoss2.ncep.noaa.gov:/lfs/h2/emc/vpppg/save/pe
	rry.shafran/EVS3/ecf/aqm/stats/run_aqm_stats.e17052798
    exec_host = nid001703/0
    exec_vnode = (nid001703:ncpus=1:mem=2097152kb)
    Hold_Types = n
    Join_Path = oe
    Keep_Files = oed
    Mail_Points = a
    mtime = Fri Oct 28 20:12:30 2022
    Output_Path = clogin01.cactus.wcoss2.ncep.noaa.gov:/lfs/h2/emc/vpppg/save/p
	erry.shafran/EVS3/ecf/aqm/stats/run_aqm_stats.o17052798
    Priority = 0
    qtime = Fri Oct 28 19:24:07 2022
    Rerunable = False
    Resource_List.alvl = 2
    Resource_List.aslr = True
    Resource_List.debug = True
    Resource_List.dfs = False
    Resource_List.hyper = False
    Resource_List.mem = 2gb
    Resource_List.ncpus = 1
    Resource_List.nodect = 1
    Resource_List.one-shot = False
    Resource_List.place = shared
    Resource_List.select = 1:ncpus=1:mem=2GB
    Resource_List.thp = True
    Resource_List.turbo = True
    Resource_List.walltime = 02:00:00
    schedselect = 1:ncpus=1:mem=2GB:prepost=False
    stime = Fri Oct 28 19:24:09 2022
    session_id = 6888
    Shell_Path_List = /bin/bash
    jobdir = /u/perry.shafran
    substate = 42
    Variable_List = PBS_O_HOME=/u/perry.shafran,PBS_O_LANG=en_US.UTF-8,
	PBS_O_LOGNAME=perry.shafran,
	PBS_O_PATH=/apps/ops/prod/nco/core/prod_util.v2.0.14/ush:/apps/prod/hp
	c-stack/intel-19.1.3.304/netcdf/4.7.4/bin:/apps/prod/hpc-stack/intel-19
	.1.3.304/hdf5/1.10.6/bin:/apps/spack/python/3.8.6/intel/19.1.3.304/pjn2
	nzkjvqgmjw4hmyz43v5x4jbxjzpk/bin:/apps/ops/para/libs/intel/19.1.3.304/m
	etplus/4.1.1/ush:/apps/ops/para/libs/intel/19.1.3.304/met/10.1.1/bin:/a
	pps/ops/para/libs/intel/19.1.3.304/gsl/2.6/bin:/pe/intel/compilers_and_
	libraries_2020.4.304/linux/bin/intel64:/pe/intel/compilers_and_librarie
	s_2020.4.304/linux/bin:/pe/intel/compilers_and_libraries_2020.4.304/lin
	ux/mpi/intel64/bin:/pe/intel/debugger_2020/gdb/intel64/bin:/opt/cray/li
	bfabric/1.11.0.0./bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt
	/sgi/bin:/usr/local/bin:/usr/bin:/bin:/usr/lib/mit/bin:/usr/lib/mit/sbi
	n:/opt/pbs/bin:/sbin:.:/u/perry.shafran/bin:/usr/sbin:/apps/prod/python
	-modules/3.8.6/intel/19.1.3.304/bin:/apps/prod/python-modules/3.8.6/int
	el/19.1.3.304/lib/python3.8/site-packages/bin,
	PBS_O_MAIL=/var/spool/mail/perry.shafran,PBS_O_SHELL=/bin/bash,
	PBS_O_WORKDIR=/lfs/h2/emc/vpppg/save/perry.shafran/EVS3/ecf/aqm/stats,
	PBS_O_SYSTEM=Linux,PBS_O_QUEUE=dev,
	PBS_O_HOST=clogin01.cactus.wcoss2.ncep.noaa.gov
    euser = perry.shafran
    egroup = emc
    hashname = 17052798.cbqs01
    queue_rank = 1666985047694
    queue_type = E
    comment = Job run at Fri Oct 28 at 19:24 on (nid001703:ncpus=1:mem=2097152k
	b)
    etime = Fri Oct 28 19:24:07 2022
    umask = 22
    run_count = 6
    eligible_time = 00:00:00
    accrue_type = 3
    Submit_arguments = run_aqm_stats.sh
    project = VERF-DEV
    run_version = 1
    Submit_Host = clogin01.cactus.wcoss2.ncep.noaa.gov


------------------------------------------------------------------
Job 17052798.cbqs01 - PBS tracejob output (for parent mom node only):

Job: 17052798.cbqs01

10/28/2022 19:24:09  M    update_job_usage: CPU usage: 0.000 secs
10/28/2022 19:24:09  M    update_job_usage: cpupercent initialized to zero
10/28/2022 19:24:09  M    update_job_usage: Memory usage: mem=0b
10/28/2022 19:24:09  M    no active tasks
10/28/2022 19:24:12  M    Started, pid = 6888
10/28/2022 19:24:32  M    update_job_usage: CPU usage: 1.546 secs
10/28/2022 19:24:32  M    update_job_usage: 17052798.cbqs01 measured interval cpupercent 6 increased job cpupercent to 6
10/28/2022 19:26:33  M    update_job_usage: CPU usage: 1.559 secs
10/28/2022 19:28:34  M    update_job_usage: CPU usage: 1.570 secs
10/28/2022 19:30:35  M    update_job_usage: CPU usage: 1.581 secs
10/28/2022 19:32:36  M    update_job_usage: CPU usage: 1.591 secs
10/28/2022 19:34:37  M    update_job_usage: CPU usage: 1.602 secs
10/28/2022 19:36:39  M    update_job_usage: CPU usage: 1.614 secs
10/28/2022 19:38:40  M    update_job_usage: CPU usage: 1.625 secs
10/28/2022 19:40:41  M    update_job_usage: CPU usage: 1.637 secs
10/28/2022 19:42:42  M    update_job_usage: CPU usage: 1.647 secs
10/28/2022 19:44:44  M    update_job_usage: CPU usage: 1.659 secs
10/28/2022 19:46:45  M    update_job_usage: CPU usage: 1.672 secs
10/28/2022 19:48:46  M    update_job_usage: CPU usage: 1.683 secs
10/28/2022 19:50:48  M    update_job_usage: CPU usage: 1.694 secs
10/28/2022 19:52:49  M    update_job_usage: CPU usage: 1.706 secs
10/28/2022 19:54:50  M    update_job_usage: CPU usage: 1.717 secs
10/28/2022 19:56:52  M    update_job_usage: CPU usage: 1.729 secs
10/28/2022 19:58:53  M    update_job_usage: CPU usage: 1.740 secs
10/28/2022 20:00:54  M    update_job_usage: CPU usage: 1.752 secs
10/28/2022 20:02:55  M    update_job_usage: CPU usage: 1.763 secs
10/28/2022 20:04:57  M    update_job_usage: CPU usage: 1.774 secs
10/28/2022 20:06:58  M    update_job_usage: CPU usage: 1.786 secs
10/28/2022 20:08:59  M    update_job_usage: CPU usage: 1.799 secs
10/28/2022 20:11:01  M    update_job_usage: CPU usage: 1.810 secs
10/28/2022 20:12:40  M    task 00000001 terminated
10/28/2022 20:12:40  M    Terminated
10/28/2022 20:12:40  M    task 00000001 cput=00:00:03
10/28/2022 20:12:40  M    kill_job
10/28/2022 20:12:40  M    nid001703 cput=00:00:02 mem=13612kb
10/28/2022 20:12:40  M    update_job_usage: CPU usage: 1.811 secs
10/28/2022 20:12:40  M    update_job_usage: Memory usage: mem=13612kb

------------------------------------------------------------------
To see full PBS log data, run: /sfs/admin/scripts/tracejob.sh 17052798.cbqs01

==================================================================
END - DEBUG INFO
==================================================================

##### Job 17052798.cbqs01 - PBS Job Script:

#PBS -N run_aqm_stats
#PBS -N run_aqm_stats
#PBS -j oe
#PBS -j oe
#PBS -S /bin/bash
#PBS -S /bin/bash
#PBS -q "dev"
#PBS -q "dev"
#PBS -A VERF-DEV
#PBS -A VERF-DEV
#PBS -l walltime=02:00:00
#PBS -l walltime=02:00:00
#PBS -l select=1:ncpus=1:mem=2GB
#PBS -l select=1:ncpus=1:mem=2GB
#PBS -l debug=true
#PBS -l debug=true

set -x

for fhr in 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23
do
   export fhr
   qsub -v cyc=$fhr /lfs/h2/emc/vpppg/save/$USER/EVS3/ecf/aqm/stats/jevs_aqm_stats.ecf
   sleep 120
done

 exit

##### End of job script
------------------------------------------------------------------
